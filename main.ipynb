{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c6dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, dcc, html, Input, Output, State, ctx, callback, ALL, MATCH, no_update, Patch, dash_table\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "from tkinter import filedialog, Tk\n",
    "from scipy.stats import gaussian_kde\n",
    "import dash_bootstrap_components as dbc\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "import joblib  \n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d2dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################################################################################################################\n",
    "def load_model():    \n",
    "    def load(model_path):\n",
    "        try:\n",
    "            model = joblib.load(model_path)\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            return None\n",
    "    root = Tk()\n",
    "    root.withdraw()  \n",
    "    file_path = filedialog.askopenfilename(title=\"   \", filetypes=[(\"Joblib files\", \"*.pkl *.joblib\"), (\"All files\", \"*.*\")])\n",
    "    model = load(file_path)\n",
    "    return model\n",
    "#################################################################################################################################\n",
    "def load_csv():\n",
    "    def load(file_path):\n",
    "        try:\n",
    "            data = pd.read_csv(file_path)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading CSV file: {e}\")\n",
    "            return None\n",
    "    root = Tk()\n",
    "    root.withdraw()  \n",
    "    file_path = filedialog.askopenfilename(title=\"      \",filetypes=[(\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")])\n",
    "    data = load(file_path)\n",
    "    return data\n",
    "##################################################################################################################################\n",
    "def test_model(model , data ):\n",
    "    try:\n",
    "        predictions = model.predict(data)\n",
    "        return predictions\n",
    "    except Exception as e:\n",
    "        print(f\"Error making predictions: {e}\")\n",
    "        return None\n",
    "##################################################################################################################################\n",
    "def compwper(model , data , output_label ):\n",
    "    try:\n",
    "        predictions = test_model(model , data.drop(columns=[output_label]))\n",
    "        return predictions , data[output_label]\n",
    "    except Exception as e:\n",
    "        print(f\"Error making predictions: {e}\")\n",
    "        return None\n",
    "##############################################################plots###############################################################\n",
    "def plot_distribution_of_clas_in_data(data, output_label):\n",
    "    try:\n",
    "        counts = data[output_label].value_counts().sort_index()\n",
    "        classes = counts.index.tolist()\n",
    "        values = counts.values.tolist()\n",
    "        total = sum(values)\n",
    "        percentages = [(v / total) * 100 for v in values]\n",
    "        percentage_labels = [f\"{p:.2f}%\" for p in percentages]\n",
    "\n",
    "        min_value = min(values)\n",
    "        max_value = max(values)\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=classes,\n",
    "            y=values,\n",
    "            marker_color='royalblue',\n",
    "            name='Class Count',\n",
    "            text=percentage_labels,\n",
    "            textposition='auto'\n",
    "        ))\n",
    "\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=-0.5,\n",
    "            x1=len(classes)-0.5,\n",
    "            y0=min_value,\n",
    "            y1=min_value,\n",
    "            line=dict(color=\"green\", dash=\"dash\"),\n",
    "        )\n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=-0.5,\n",
    "            x1=len(classes)-0.5,\n",
    "            y0=max_value,\n",
    "            y1=max_value,\n",
    "            line=dict(color=\"red\", dash=\"dash\"),\n",
    "        )\n",
    "\n",
    "        fig.add_annotation(\n",
    "            x=len(classes) - 1, \n",
    "            y=(min_value + max_value) / 2,\n",
    "            ax=len(classes) - 1,\n",
    "            ay=min_value,\n",
    "            xref='x', yref='y',\n",
    "            axref='x', ayref='y',\n",
    "            showarrow=True,\n",
    "            arrowhead=3,\n",
    "            arrowsize=1,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor=\"orange\",\n",
    "            text=f\"Diff: {max_value - min_value}\",\n",
    "            font=dict(color=\"orange\")\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Class Distribution of '{output_label}' with Min/Max Lines and Percentages\",\n",
    "            xaxis_title=\"Class\",\n",
    "            yaxis_title=\"Count\",\n",
    "            showlegend=False\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "    except Exception as e:\n",
    "        print(f\"Error in plotting class balance: {e}\")\n",
    "    \n",
    "\n",
    "##################################################################################################################################\n",
    "\n",
    "external_stylesheets = [\n",
    "    \"https://smart-radius.com/assets/libs/bootstrap/css/bootstrap.rtl.min.css\",\n",
    "    \"https://smart-radius.com/assets/css/styles.css\",\n",
    "    \"https://smart-radius.com/assets/css/icons.min.css\",\n",
    "    \"https://smart-radius.com/assets/css/font_cairo.css\"\n",
    "]\n",
    "\n",
    "#######################################################################################################################################\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "def train_machine_learning_model(X_train, y_train, X_test, y_test, model_name):\n",
    "    print(f\"Starting Machine Learning Model training: {model_name}.\")\n",
    "    model_path = None\n",
    "    accuracy = np.random.uniform(0.90, 0.99)\n",
    "    time.sleep(3)\n",
    "    model_filename = f\"{model_name}_model.joblib\"\n",
    "    model_path = os.path.join(MODEL_DIR, model_filename)\n",
    "    try:\n",
    "        with open(model_path, \"w\") as f:\n",
    "            f.write(f\"Placeholder for ML model: {model_name}\\nSimulated Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Machine Learning Model {model_name} trained and saved to: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Machine Learning Model {model_name}: {e}\")\n",
    "        return f\"Machine Learning Model {model_name} trained but failed to save: {e}\", None, 0.0\n",
    "    return f\"Machine Learning Model {model_name} trained successfully (simulation). Accuracy: {accuracy:.4f}\", model_path, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_deep_learning_model(X_train, y_train, X_test, y_test, layer_configs, num_layers):\n",
    "    print(f\"Starting Deep Learning Model training with {num_layers} layers.\")\n",
    "    model_path = None\n",
    "    accuracy = np.random.uniform(0.7, 0.95)  \n",
    "    time.sleep(5)\n",
    "    model_filename = \"deep_learning_model_placeholder.txt\"\n",
    "    model_path = os.path.join(MODEL_DIR, model_filename)\n",
    "    try:\n",
    "        with open(model_path, \"w\") as f:\n",
    "            f.write(f\"Placeholder for DL model. Configs: {layer_configs}\\nSimulated Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Deep Learning Model trained and saved to: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Deep Learning Model: {e}\")\n",
    "        return f\"Deep Learning Model trained but failed to save: {e}\", None, 0.0\n",
    "    return f\"Deep Learning Model trained successfully (simulation). Accuracy: {accuracy:.4f}\", model_path, accuracy\n",
    "\n",
    "##################################################################################\n",
    "def plot_3d_surface_with_dropdown(x, y, z, surface_color=None):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Surface(\n",
    "        z=z,\n",
    "        colorscale=\"Viridis\",\n",
    "        surfacecolor=surface_color if surface_color is not None else z\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        height=900,\n",
    "        autosize=False,\n",
    "        margin=dict(t=0, b=0, l=0, r=0),\n",
    "        template=\"plotly_white\",\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                direction=\"left\",\n",
    "                buttons=[\n",
    "                    dict(args=[\"type\", \"surface\"], label=\"3D Surface\", method=\"restyle\"),\n",
    "                    dict(args=[\"type\", \"heatmap\"], label=\"Heatmap\", method=\"restyle\")\n",
    "                ],\n",
    "                pad={\"r\": 10, \"t\": 10},\n",
    "                showactive=True,\n",
    "                x=0.11,\n",
    "                xanchor=\"left\",\n",
    "                y=1.1,\n",
    "                yanchor=\"top\"\n",
    "            ),\n",
    "        ],\n",
    "        annotations=[\n",
    "            dict(text=\"Trace type:\", showarrow=False, x=0, y=1.08, yref=\"paper\", align=\"left\")\n",
    "        ]\n",
    "    )\n",
    "    fig.update_scenes(aspectratio=dict(x=1, y=1, z=0.7), aspectmode=\"manual\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3acb9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_distribution_of_clas_in_data(data, output_label):\n",
    "    try:\n",
    "        if pd.api.types.is_numeric_dtype(data[output_label]):\n",
    "            values = data[output_label].dropna()\n",
    "            \n",
    "            mean_val = values.mean()\n",
    "            median_val = values.median()\n",
    "            mode_val = values.mode()[0] if not values.mode().empty else None\n",
    "            \n",
    "            # IQR Calculation for Outliers\n",
    "            Q1 = np.percentile(values, 25)\n",
    "            Q3 = np.percentile(values, 75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers = values[(values < lower_bound) | (values > upper_bound)]\n",
    "\n",
    "            # Histogram\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Histogram(\n",
    "                x=values,\n",
    "                nbinsx=30,\n",
    "                name='Histogram',\n",
    "                marker_color='lightblue',\n",
    "                opacity=0.7\n",
    "            ))\n",
    "\n",
    "            # KDE Curve\n",
    "            kde = gaussian_kde(values)\n",
    "            x_range = np.linspace(values.min(), values.max(), 500)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_range,\n",
    "                y=kde(x_range) * len(values) * (values.max()-values.min()) / 30,\n",
    "                mode='lines',\n",
    "                name='KDE',\n",
    "                line=dict(color='darkblue', width=2)\n",
    "            ))\n",
    "\n",
    "            # Add Mean / Median / Mode\n",
    "            fig.add_vline(x=mean_val, line=dict(color=\"blue\", dash=\"dot\"), annotation_text=f\"Mean: {mean_val:.2f}\", annotation_position=\"top\")\n",
    "            fig.add_vline(x=median_val, line=dict(color=\"green\", dash=\"dash\"), annotation_text=f\"Median: {median_val:.2f}\", annotation_position=\"top\")\n",
    "            if mode_val is not None:\n",
    "                fig.add_vline(x=mode_val, line=dict(color=\"orange\", dash=\"solid\"), annotation_text=f\"Mode: {mode_val:.2f}\", annotation_position=\"top\")\n",
    "\n",
    "            # Outlier markers\n",
    "            if not outliers.empty:\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=outliers,\n",
    "                    y=[0]*len(outliers),\n",
    "                    mode='markers',\n",
    "                    marker=dict(color='red', size=8, symbol='x'),\n",
    "                    name='Outliers',\n",
    "                    showlegend=True\n",
    "                ))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f\"Numerical Distribution of '{output_label}' with Stats & Outliers\",\n",
    "                xaxis_title=output_label,\n",
    "                yaxis_title=\"Count\",\n",
    "                showlegend=True\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # Categorical as before\n",
    "            counts = data[output_label].value_counts().sort_index()\n",
    "            classes = counts.index.tolist()\n",
    "            values = counts.values.tolist()\n",
    "            total = sum(values)\n",
    "            percentages = [(v / total) * 100 for v in values]\n",
    "            percentage_labels = [f\"{p:.2f}%\" for p in percentages]\n",
    "\n",
    "            min_value = min(values)\n",
    "            max_value = max(values)\n",
    "\n",
    "            fig = go.Figure()\n",
    "            fig.add_trace(go.Bar(\n",
    "                x=classes,\n",
    "                y=values,\n",
    "                marker_color='royalblue',\n",
    "                name='Class Count',\n",
    "                text=percentage_labels,\n",
    "                textposition='auto'\n",
    "            ))\n",
    "\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=-0.5,\n",
    "                x1=len(classes)-0.5,\n",
    "                y0=min_value,\n",
    "                y1=min_value,\n",
    "                line=dict(color=\"green\", dash=\"dash\"),\n",
    "            )\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=-0.5,\n",
    "                x1=len(classes)-0.5,\n",
    "                y0=max_value,\n",
    "                y1=max_value,\n",
    "                line=dict(color=\"red\", dash=\"dash\"),\n",
    "            )\n",
    "\n",
    "            fig.add_annotation(\n",
    "                x=len(classes) - 1, \n",
    "                y=(min_value + max_value) / 2,\n",
    "                ax=len(classes) - 1,\n",
    "                ay=min_value,\n",
    "                xref='x', yref='y',\n",
    "                axref='x', ayref='y',\n",
    "                showarrow=True,\n",
    "                arrowhead=3,\n",
    "                arrowsize=1,\n",
    "                arrowwidth=2,\n",
    "                arrowcolor=\"orange\",\n",
    "                text=f\"Diff: {max_value - min_value}\",\n",
    "                font=dict(color=\"orange\")\n",
    "            )\n",
    "\n",
    "            fig.update_layout(\n",
    "                title=f\"Class Distribution of '{output_label}' with Min/Max Lines and Percentages\",\n",
    "                xaxis_title=\"Class\",\n",
    "                yaxis_title=\"Count\",\n",
    "                showlegend=False\n",
    "            )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in plotting distribution: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed8b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "global global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07870634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    app = html.Div([\n",
    "    html.H1(\"Model Performance Analyzer\"),\n",
    "\n",
    "    # Hidden Divs for storing intermediate data\n",
    "    dcc.Store(id='data-store1'),  # To store the uploaded DataFrame as JSON\n",
    "    dcc.Store(id='model-status-store'), # To store a trigger when model is uploaded\n",
    "    dcc.Store(id='processed-data-store'), # To store DataFrame with predictions\n",
    "    dcc.Store(id='metrics-store'), # To store calculated metrics\n",
    "\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.H3(\"Step 1: Upload Data (CSV)\"),\n",
    "            dcc.Upload(\n",
    "                id='upload-data',\n",
    "                children=html.Div(['Drag and Drop or ', html.A('Select CSV File')]),\n",
    "                style={\n",
    "                    'width': '95%', 'height': '60px', 'lineHeight': '60px',\n",
    "                    'borderWidth': '1px', 'borderStyle': 'dashed',\n",
    "                    'borderRadius': '5px', 'textAlign': 'center', 'margin': '10px'\n",
    "                },\n",
    "                multiple=False # Allow only single file upload\n",
    "            ),\n",
    "            html.Div(id='output-data-upload-status'),\n",
    "        ], style={'width': '48%', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "\n",
    "        html.Div([\n",
    "            html.H3(\"Step 2: Upload Model File (.pkl or .joblib)\"),\n",
    "            dcc.Upload(\n",
    "                id='upload-model',\n",
    "                children=html.Div(['Drag and Drop or ', html.A('Select Model File')]),\n",
    "                style={\n",
    "                    'width': '95%', 'height': '60px', 'lineHeight': '60px',\n",
    "                    'borderWidth': '1px', 'borderStyle': 'dashed',\n",
    "                    'borderRadius': '5px', 'textAlign': 'center', 'margin': '10px'\n",
    "                },\n",
    "                multiple=False\n",
    "            ),\n",
    "            html.Div(id='output-model-upload-status'),\n",
    "        ], style={'width': '48%', 'float': 'right', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "    ]),\n",
    "\n",
    "    html.Hr(),\n",
    "\n",
    "    html.Div(id='analysis-section', children=[\n",
    "        html.Div([\n",
    "            html.Label(\"Step 3: Select Column for Analysis:\"),\n",
    "            dcc.Dropdown(id='column-dropdown', placeholder=\"Upload data first\"),\n",
    "        ], style={'width': '48%', 'display': 'inline-block', 'marginBottom': '20px'}),\n",
    "\n",
    "        html.Hr(),\n",
    "\n",
    "        # Plot 1\n",
    "        html.Div([\n",
    "            html.H3(\"Plot 1: Prediction Correctness by Category\"),\n",
    "            dcc.Graph(id='plot1-bar-chart')\n",
    "        ], style={'width': '48%', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "\n",
    "        # Plot 2\n",
    "        html.Div([\n",
    "            html.H3(\"Plot 2: Error Distribution by Category\"),\n",
    "            dcc.Graph(id='plot2-pie-chart')\n",
    "        ], style={'width': '48%', 'float': 'right', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "\n",
    "        html.Hr(style={'clear': 'both', 'marginTop': '20px', 'marginBottom': '20px'}),\n",
    "\n",
    "        # Plot 3\n",
    "        html.Div([\n",
    "            html.H3(\"Plot 3: Overall Model Performance Indicators\"),\n",
    "            dcc.Graph(id='plot3-indicators')\n",
    "        ], style={'width': '98%', 'margin': 'auto'})\n",
    "    ], style={'display': 'none'}) # Initially hidden until data and model are ready\n",
    "])\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8613dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_home_layout():\n",
    "    from dash import  dcc, html\n",
    "    import pandas as pd\n",
    "    import dash_bootstrap_components as dbc\n",
    "    app= html.Div([\n",
    "    dcc.Store(id='data-store'), # لتخزين بيانات الـ DataFrame\n",
    "\n",
    "    html.H1(\" Home \", style={'textAlign': 'center', 'color': '#333'}),\n",
    "\n",
    "    # قسم رفع الملف والرسم البياني التوزيعي\n",
    "    html.Div([\n",
    "        html.Label(\"Upload CSV File:\", className=\"text-white\"),\n",
    "        dcc.Upload(\n",
    "            id='upload-data',\n",
    "            children=html.Div(['Drag and drop or ', html.A('Select from your device')]),\n",
    "            style={\n",
    "                'width': '100%', 'height': '60px', 'lineHeight': '60px',\n",
    "                'borderWidth': '1px', 'borderStyle': 'dashed',\n",
    "                'borderRadius': '5px', 'textAlign': 'center', 'margin-bottom': '10px'\n",
    "            },\n",
    "            multiple=False\n",
    "        ),\n",
    "        html.Label(\"Select Column for Distribution Plot:\", className=\"text-white mt-2\"),\n",
    "        dcc.Dropdown(id='x-axis-dropdown', placeholder='Select X-axis column'),\n",
    "        dcc.Graph(id='scatter-chart')\n",
    "    ], className=\"container p-4 bg-light text-right\", dir=\"rtl\"), # text-right و dir=\"rtl\" لليمين لليسار\n",
    "\n",
    "\n",
    "    html.Label(\"Select Columns for 3D Plot:\", className=\"text-dark mt-3 d-block text-center\"), # تعديل ليكون ظاهر\n",
    "    html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='x-axis-dropdown1',\n",
    "        placeholder='Select X-axis column (3D)',\n",
    "        style={'width': '250px', 'fontSize': '18px'}\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='y-axis-dropdown1',\n",
    "        placeholder='Select Y-axis column (3D)',\n",
    "        style={'width': '250px', 'fontSize': '18px'}\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='z-axis-dropdown1',\n",
    "        placeholder='Select Z-axis column (3D)',\n",
    "        style={'width': '250px', 'fontSize': '18px'}\n",
    "    ),\n",
    "    dcc.Dropdown(\n",
    "        id='color-dropdown',\n",
    "        placeholder='Select Color column (3D - optional)',\n",
    "        style={'width': '250px', 'fontSize': '18px'}\n",
    "    ),\n",
    "], style={\n",
    "    'display': 'flex',\n",
    "    'gap': '20px',\n",
    "    'flexWrap': 'wrap',\n",
    "    'padding': '20px',\n",
    "    'justifyContent': 'center',\n",
    "    'alignItems': 'center',\n",
    "}),\n",
    "    dcc.Graph(id='3D-chart'),\n",
    "    html.Div([\n",
    "        html.Button(\"download\", id=\"download-data-button\", className=\"btn btn-success mt-3\"),\n",
    "        dcc.Download(id=\"download-dataframe-csv\")\n",
    "    ], style={'textAlign': 'center', 'padding': '20px'})\n",
    "\n",
    "], style={'backgroundColor': '#f8f9fa'}) \n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087046b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def update_output(n_clicks, value):\n",
    "#     if n_clicks == 0:\n",
    "#         return \"\"\n",
    "#     if not value:\n",
    "#         return \"⚠️ لم يتم إدخال أي نص!\"\n",
    "#     return f\"✅ تم إدخال النص: {value}\" \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_another_page_layout():\n",
    "    try:\n",
    "        df = pd.read_csv(\"anime_ed.csv\")\n",
    "    except FileNotFoundError:\n",
    "    \n",
    "        print(\"WARN: 'anime_ed.csv' not found. Using placeholder data.\")\n",
    "        data_placeholder = {\n",
    "            'name': ['Anime A', 'Anime B', 'Anime C', 'Anime D', 'Anime E', 'Anime F'],\n",
    "            'genres': ['Action,Adventure', 'Comedy,Slice of Life', 'Action,Drama', 'Sci-Fi,Adventure', 'Comedy,Drama', 'Fantasy,Magic'],\n",
    "            'rating': [8.5, 7.9, 9.0, 8.2, 7.5, 8.8],\n",
    "        \n",
    "        }\n",
    "        df = pd.DataFrame(data_placeholder)\n",
    "\n",
    "\n",
    "    df[\"genres_list\"] = df[\"genre\"].fillna(\"\").astype(str).str.split(',')\n",
    "    df[\"genres_list\"] = df[\"genres_list\"].apply(lambda genre_list: sorted([g.strip() for g in genre_list if g.strip()])) # Sort for consistency\n",
    "\n",
    "\n",
    "    all_unique_genres = sorted(list(set(g for sublist in df[\"genres_list\"] for g in sublist)))\n",
    "    for genre_col in all_unique_genres:\n",
    "        df[genre_col] = df[\"genres_list\"].apply(lambda L: int(genre_col in L))\n",
    "    app = dbc.Container([\n",
    "        dbc.Row(dbc.Col(html.H1(\"Anime Recommendation System\", className=\"text-center text-primary my-4 fw-bold\"), width=12)),\n",
    "\n",
    "        dbc.Card([\n",
    "            dbc.CardBody([\n",
    "                dbc.Row([\n",
    "                    dbc.Col([\n",
    "                        html.Label(\"Choose Recommendation Mode:\", className=\"fw-bold\"),\n",
    "                        dcc.Dropdown(\n",
    "                            id=\"anime-mode-dropdown\",\n",
    "                            options=[\n",
    "                                {\"label\": \"Based on Mood/Genre\", \"value\": \"mood\"},\n",
    "                                {\"label\": \"Based on Previously Watched Anime\", \"value\": \"watched\"}\n",
    "                            ],\n",
    "                            value=\"mood\",\n",
    "                            clearable=False\n",
    "                        )\n",
    "                    ], md=6),\n",
    "                    dbc.Col([\n",
    "                        html.Label(\"Number of Recommendations:\", className=\"fw-bold\"),\n",
    "                        dcc.Input(\n",
    "                            id=\"num-recommendations-input\",\n",
    "                            type=\"number\",\n",
    "                            value=5,\n",
    "                            min=1,\n",
    "                            max=20,\n",
    "                            step=1,\n",
    "                            className=\"form-control\" \n",
    "                        )\n",
    "                    ], md=6)\n",
    "                ], className=\"mb-3\"),\n",
    "                html.Div(id=\"anime-sub-selection-area\")\n",
    "            ])\n",
    "        ], className=\"mb-4 shadow-sm\"),\n",
    "\n",
    "        dbc.Row(dbc.Col(html.H2(\"Recommendations\", className=\"mt-4 mb-3 text-secondary\"), width=12)),\n",
    "        dcc.Loading(\n",
    "            id=\"loading-results\",\n",
    "            type=\"default\", \n",
    "            children=[\n",
    "                html.Div(id=\"anime-recommendation-results\", className=\"mt-2\")\n",
    "            ],\n",
    "            overlay_style={\"visibility\":\"visible\", \"opacity\": 0.2, \"backgroundColor\": \"white\"} \n",
    "        )\n",
    "    ], fluid=False, className=\"py-4\") \n",
    "\n",
    "    return app\n",
    "\n",
    "def get_contact_layout(df):\n",
    "\n",
    "    def generate_data_report(df):\n",
    "        report_sections = []\n",
    "\n",
    "        # Null values\n",
    "        null_counts = df.isnull().sum().reset_index()\n",
    "        null_counts.columns = ['Column', 'Missing Values']\n",
    "        report_sections.append(html.H4(\"Missing Values Per Column:\"))\n",
    "        report_sections.append(dash_table.DataTable(\n",
    "            data=null_counts.to_dict('records'),\n",
    "            columns=[{'name': i, 'id': i} for i in null_counts.columns],\n",
    "            style_table={'overflowX': 'auto'}\n",
    "        ))\n",
    "        report_sections.append(html.Hr())\n",
    "\n",
    "        # Outliers (IQR method)\n",
    "        outlier_columns = []\n",
    "        numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "        if not numerical_cols.empty:\n",
    "            for col in numerical_cols:\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                if ((df[col] < lower_bound) | (df[col] > upper_bound)).any():\n",
    "                    outlier_columns.append(col)\n",
    "\n",
    "        report_sections.append(html.H4(\"Columns with Potential Outliers (IQR method):\"))\n",
    "        if outlier_columns:\n",
    "            report_sections.append(html.Ul([html.Li(col) for col in outlier_columns]))\n",
    "        else:\n",
    "            report_sections.append(html.P(\"No outliers detected using IQR in numeric columns.\"))\n",
    "        report_sections.append(html.Hr())\n",
    "\n",
    "        # General types\n",
    "        data_types_general = []\n",
    "        for col in df.columns:\n",
    "            dtype = 'Numeric' if pd.api.types.is_numeric_dtype(df[col]) else 'Text/Categorical'\n",
    "            data_types_general.append({'Column': col, 'General Type': dtype})\n",
    "        report_sections.append(html.H4(\"General Data Type per Column:\"))\n",
    "        report_sections.append(dash_table.DataTable(\n",
    "            data=data_types_general,\n",
    "            columns=[{'name': 'Column', 'id': 'Column'}, {'name': 'General Type', 'id': 'General Type'}],\n",
    "            style_table={'overflowX': 'auto'}\n",
    "        ))\n",
    "        report_sections.append(html.Hr())\n",
    "\n",
    "        # Specific types\n",
    "        data_types_specific = df.dtypes.reset_index()\n",
    "        data_types_specific.columns = ['Column', 'Specific Type']\n",
    "        data_types_specific['Specific Type'] = data_types_specific['Specific Type'].astype(str)\n",
    "        report_sections.append(html.H4(\"Specific Data Type per Column:\"))\n",
    "        report_sections.append(dash_table.DataTable(\n",
    "            data=data_types_specific.to_dict('records'),\n",
    "            columns=[{'name': i, 'id': i} for i in data_types_specific.columns],\n",
    "            style_table={'overflowX': 'auto'}\n",
    "        ))\n",
    "        report_sections.append(html.Hr())\n",
    "\n",
    "        # Correlation Heatmap\n",
    "        if not numerical_cols.empty:\n",
    "            corr_matrix = df[numerical_cols].corr()\n",
    "            fig = px.imshow(\n",
    "                corr_matrix,\n",
    "                text_auto=True,\n",
    "                aspect=\"auto\",\n",
    "                title=\"Correlation Heatmap Between Numeric Columns\",\n",
    "                color_continuous_scale='RdBu',\n",
    "                zmin=-1,\n",
    "                zmax=1\n",
    "            )\n",
    "            report_sections.append(html.H4(\"Correlation Heatmap:\"))\n",
    "            report_sections.append(dcc.Graph(figure=fig))\n",
    "\n",
    "        return html.Div(report_sections)\n",
    "\n",
    "    # App layout\n",
    "    app = html.Div([\n",
    "        html.H2(\"Fixed Data Report\", style={'textAlign': 'center'}),\n",
    "        generate_data_report(df)\n",
    "    ])\n",
    "    return app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2d4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e296291",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_activation_functions = [\n",
    "        {'label': 'ReLU', 'value': 'relu'},\n",
    "        {'label': 'Sigmoid', 'value': 'sigmoid'},\n",
    "        {'label': 'Tanh', 'value': 'tanh'},\n",
    "        {'label': 'Softmax', 'value': 'softmax'},\n",
    "        {'label': 'Linear', 'value': 'linear'},\n",
    "        {'label': 'Leaky ReLU', 'value': 'leaky_relu'},\n",
    "        {'label': 'ELU (Exponential Linear Unit)', 'value': 'elu'},\n",
    "        {'label': 'None (No activation)', 'value': 'none'}\n",
    "    ]\n",
    "\n",
    "common_dense_units = [\n",
    "        {'label': '1 Unit/Class', 'value': 1},\n",
    "        {'label': '2 Units/Classes', 'value': 2},\n",
    "        {'label': '3 Units/Classes', 'value': 3},\n",
    "        {'label': '4 Units/Classes', 'value': 4},\n",
    "        {'label': '8 Units', 'value': 8},\n",
    "        {'label': '10 Units/Classes', 'value': 10},\n",
    "        {'label': '16 Units', 'value': 16},\n",
    "        {'label': '24 Units', 'value': 24},\n",
    "        {'label': '32 Units', 'value': 32},\n",
    "        {'label': '48 Units', 'value': 48},\n",
    "        {'label': '64 Units', 'value': 64},\n",
    "        {'label': '96 Units', 'value': 96},\n",
    "        {'label': '128 Units', 'value': 128},\n",
    "        {'label': '192 Units', 'value': 192},\n",
    "        {'label': '256 Units', 'value': 256},\n",
    "        {'label': '384 Units', 'value': 384},\n",
    "        {'label': '512 Units', 'value': 512},\n",
    "        {'label': '768 Units', 'value': 768},\n",
    "        {'label': '1024 Units', 'value': 1024},\n",
    "        {'label': '2048 Units', 'value': 2048},\n",
    "    ]\n",
    "def get_data_exploration_layout():\n",
    "    MODEL_DIR = \"trained_models\"\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    \n",
    "    global global_df\n",
    "\n",
    "    # global_df = pd.DataFrame(global_df)\n",
    "\n",
    "    def train_deep_learning_model(X_train, y_train, X_test, y_test, layer_configs, num_layers):\n",
    "        print(f\"Starting Deep Learning Model training with {num_layers} layers.\")\n",
    "        model_path = None\n",
    "        accuracy = np.random.uniform(0.7, 0.95) # Simulated accuracy\n",
    "\n",
    "        time.sleep(5) \n",
    "        \n",
    "        model_filename = \"deep_learning_model_placeholder.txt\"\n",
    "        model_path = os.path.join(MODEL_DIR, model_filename)\n",
    "        try:\n",
    "            with open(model_path, \"w\") as f:\n",
    "                f.write(f\"Placeholder for DL model. Configs: {layer_configs}\\nSimulated Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Deep Learning Model trained and saved to: {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving Deep Learning Model: {e}\")\n",
    "            return f\"Deep Learning Model trained but failed to save: {e}\", None, 0.0\n",
    "        \n",
    "        print(\"Deep Learning Model training completed (simulation).\")\n",
    "        return f\"Deep Learning Model trained successfully (simulation). Accuracy: {accuracy:.4f}\", model_path, accuracy\n",
    "\n",
    "\n",
    "    def train_machine_learning_model(X_train, y_train, X_test, y_test, model_name):\n",
    "        print(f\"Starting Machine Learning Model training: {model_name}.\")\n",
    "        model_path = None\n",
    "        accuracy = np.random.uniform(0.65, 0.90)\n",
    "        time.sleep(3)\n",
    "\n",
    "        model_filename = f\"{model_name}_model.joblib\"\n",
    "        model_path = os.path.join(MODEL_DIR, model_filename)\n",
    "        try:\n",
    "            with open(model_path, \"w\") as f:\n",
    "                f.write(f\"Placeholder for ML model: {model_name}\\nSimulated Accuracy: {accuracy:.4f}\")\n",
    "            print(f\"Machine Learning Model {model_name} trained and saved to: {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving Machine Learning Model {model_name}: {e}\")\n",
    "            return f\"Machine Learning Model {model_name} trained but failed to save: {e}\", None, 0.0\n",
    "        \n",
    "        print(f\"Machine Learning Model {model_name} training completed.\")\n",
    "        return f\"Machine Learning Model {model_name} trained successfully (simulation). Accuracy: {accuracy:.4f}\", model_path, accuracy\n",
    "\n",
    "\n",
    "    # app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP], suppress_callback_exceptions=True)\n",
    "\n",
    "    common_activation_functions = [\n",
    "        {'label': 'ReLU', 'value': 'relu'},\n",
    "        {'label': 'Sigmoid', 'value': 'sigmoid'},\n",
    "        {'label': 'Tanh', 'value': 'tanh'},\n",
    "        {'label': 'Softmax', 'value': 'softmax'},\n",
    "        {'label': 'Linear', 'value': 'linear'},\n",
    "        {'label': 'Leaky ReLU', 'value': 'leaky_relu'},\n",
    "        {'label': 'ELU (Exponential Linear Unit)', 'value': 'elu'},\n",
    "        {'label': 'None (No activation)', 'value': 'none'}\n",
    "    ]\n",
    "\n",
    "    common_dense_units = [\n",
    "        {'label': '1 Unit/Class', 'value': 1},\n",
    "        {'label': '2 Units/Classes', 'value': 2},\n",
    "        {'label': '3 Units/Classes', 'value': 3},\n",
    "        {'label': '4 Units/Classes', 'value': 4},\n",
    "        {'label': '8 Units', 'value': 8},\n",
    "        {'label': '10 Units/Classes', 'value': 10},\n",
    "        {'label': '16 Units', 'value': 16},\n",
    "        {'label': '24 Units', 'value': 24},\n",
    "        {'label': '32 Units', 'value': 32},\n",
    "        {'label': '48 Units', 'value': 48},\n",
    "        {'label': '64 Units', 'value': 64},\n",
    "        {'label': '96 Units', 'value': 96},\n",
    "        {'label': '128 Units', 'value': 128},\n",
    "        {'label': '192 Units', 'value': 192},\n",
    "        {'label': '256 Units', 'value': 256},\n",
    "        {'label': '384 Units', 'value': 384},\n",
    "        {'label': '512 Units', 'value': 512},\n",
    "        {'label': '768 Units', 'value': 768},\n",
    "        {'label': '1024 Units', 'value': 1024},\n",
    "        {'label': '2048 Units', 'value': 2048},\n",
    "    ]\n",
    "\n",
    "    ml_output_column_options = [{'label': col, 'value': col} for col in global_df.columns]\n",
    "\n",
    "    app = dbc.Container([\n",
    "        dcc.Store(id='deep-learning-layer-configs-store'),\n",
    "        dcc.Store(id='trained-model-path-store', data=None),\n",
    "        dcc.Download(id=\"download-model-component\"),\n",
    "\n",
    "        dbc.Row(\n",
    "            dbc.Col(html.H2(\"Model Training \", className=\"text-center bg-light p-2 mb-4\"), width=12)\n",
    "        ),\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                html.H4(\"Deep Learning Model\"),\n",
    "                dbc.Card(\n",
    "                    dbc.CardBody([\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(html.Label(\"Number of Layers:\"), width=6),\n",
    "                            dbc.Col(dcc.Input(id='dl-num-layers', type='number', min=1, step=1, value=1, className=\"mb-2\"), width=6),\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(html.Label(\"Layer Configuration:\"), width=\"auto\", className=\"me-2 align-self-center\"),\n",
    "                            dbc.Col(dbc.Button(\"Configure Layers\", id=\"open-layer-config-modal-button\", color=\"info\", className=\"mb-2\"), width=\"auto\"),\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(html.Label(\"Target Column (y):\"), width=5),\n",
    "                            dbc.Col(dcc.Dropdown(\n",
    "                                    id='dl-output-column', \n",
    "                                    options=ml_output_column_options,\n",
    "                                    placeholder=\"Select target column for DL\",\n",
    "                                    className=\"mb-2\"\n",
    "                                ), width=7),\n",
    "                        ])\n",
    "                    ])\n",
    "                , className=\"mb-4\")\n",
    "            ], md=6),\n",
    "            dbc.Col([\n",
    "                html.H4(\"Machine Learning Model\"),\n",
    "                dbc.Card(\n",
    "                    dbc.CardBody([\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(html.Label(\"Model Name:\"), width=5),\n",
    "                            dbc.Col(dcc.Dropdown(\n",
    "                                id='ml-model-name',\n",
    "                                options=[\n",
    "                                    {'label': 'Linear Regression', 'value': 'linear_regression'},\n",
    "                                    {'label': 'Logistic Regression', 'value': 'logistic_regression'},\n",
    "                                    {'label': 'Support Vector Machine (SVM)', 'value': 'svm'},\n",
    "                                    {'label': 'Random Forest', 'value': 'random_forest'},\n",
    "                                    {'label': 'Gradient Boosting', 'value': 'gradient_boosting'},\n",
    "                                ],\n",
    "                                placeholder=\"Select a model\",\n",
    "                                className=\"mb-2\"\n",
    "                            ), width=7),\n",
    "                        ]),\n",
    "                        dbc.Row([\n",
    "                            dbc.Col(html.Label(\"Target Column (y):\"), width=5),\n",
    "                            dbc.Col(dcc.Dropdown(\n",
    "                                    id='ml-output-column',\n",
    "                                    options=ml_output_column_options,\n",
    "                                    placeholder=\"Select output column\",\n",
    "                                    className=\"mb-2\"\n",
    "                                ), width=7),\n",
    "                        ]),\n",
    "                    ])\n",
    "                , className=\"mb-4\")\n",
    "            ], md=6),\n",
    "        ]),\n",
    "        dbc.Row([\n",
    "            dbc.Col([\n",
    "                dbc.Checkbox(\n",
    "                    id=\"train-dl-checkbox\",\n",
    "                    label=\"Train Deep Learning Model\",\n",
    "                    value=False,\n",
    "                    className=\"me-3\"\n",
    "                ),\n",
    "                dbc.Checkbox(\n",
    "                    id=\"train-ml-checkbox\",\n",
    "                    label=\"Train Machine Learning Model\",\n",
    "                    value=False, \n",
    "                    className=\"me-3\" \n",
    "                ),\n",
    "            ], width=\"auto\", className=\"text-md-end align-self-center\"),\n",
    "            dbc.Col(\n",
    "                dbc.Button(\"Train Selected Models\", id='train-button', color=\"primary\", n_clicks=0),\n",
    "                width=\"auto\", className=\"text-md-start mt-2 mt-md-0 align-self-center\"\n",
    "            )\n",
    "        ], justify=\"center\", className=\"mt-3 mb-3 align-items-center\"),\n",
    "\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dcc.Loading(\n",
    "                    id=\"loading-output\",\n",
    "                    type=\"default\",\n",
    "                    children=html.Div(id='output-message', className=\"mt-3 text-center\"),\n",
    "                ), \n",
    "                width=12\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                html.Div([\n",
    "                    dbc.Button(\n",
    "                        \"Download Trained Model\", \n",
    "                        id=\"download-model-button\", \n",
    "                        color=\"success\", \n",
    "                        className=\"mt-3\", \n",
    "                        n_clicks=0,\n",
    "                        style={'display': 'none'} \n",
    "                    )\n",
    "                ], id='download-button-container', className=\"text-center\"),\n",
    "                width=12\n",
    "            )\n",
    "        ),\n",
    "        dbc.Modal(\n",
    "            [\n",
    "                dbc.ModalHeader(dbc.ModalTitle(\"Configure Deep Learning Layers\")),\n",
    "                dbc.ModalBody(html.Div(id=\"dynamic-layer-input-container\")),\n",
    "                dbc.ModalFooter(\n",
    "                    [\n",
    "                        dbc.Button(\"Save Configuration\", id=\"save-layer-config-button\", color=\"success\", className=\"ms-auto\", n_clicks=0),\n",
    "                        dbc.Button(\"Close\", id=\"close-layer-config-modal-button\", color=\"secondary\", className=\"ms-auto\", n_clicks=0)\n",
    "                    ]\n",
    "                ),\n",
    "            ],\n",
    "            id=\"layer-config-modal\",\n",
    "            is_open=False,\n",
    "            size=\"lg\",\n",
    "            backdrop=\"static\",\n",
    "        ),\n",
    "    ], fluid=True)\n",
    "\n",
    "    return app\n",
    "########################################################################################################################\n",
    "################################################################################################################################################################################################################################################\n",
    "########################################################################################################################\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924711d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5029727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing_layout():\n",
    "    global global_df\n",
    "    # global_df=global_df\n",
    "    app1= html.Div([\n",
    "        html.Div([\n",
    "            html.H2(\"Preprocessing Data\", className=\"text-center my-4\"),\n",
    "            html.Br(),\n",
    "            dcc.Dropdown(\n",
    "                options=[\n",
    "                    {\"label\": \"Remove null values\", \"value\": \"remove_null\"},\n",
    "                    {\"label\": \"Normalization\", \"value\": \"Normalization\"},\n",
    "                    {\"label\": \"Standardization\", \"value\": \"Standardization\"},\n",
    "                    {\"label\": \"Encoding\", \"value\": \"Encoding\"},\n",
    "                    {\"label\": \"Remove duplicates\", \"value\": \"remove_duplicates\"},\n",
    "                    {\"label\": \"Drop specific feature\", \"value\": \"drop_feature\"},\n",
    "                    {\"label\": \"Dimensionality Reduction (PCA)\", \"value\": \"pca\"},\n",
    "                ],\n",
    "                value=[],\n",
    "                multi=True,\n",
    "                placeholder=\"Select preprocessing methods\",\n",
    "                id=\"preprocessing-dropdown\"\n",
    "            ),\n",
    "            html.Br(),\n",
    "            html.Div([\n",
    "                html.Button(\"Configure & Run\", id=\"open-modal-button\", className=\"btn btn-primary\"),\n",
    "                html.Button(\"Download New Data\", id=\"download-new-data-button\", className=\"btn btn-success\"), \n",
    "            ], className=\"d-flex justify-content-center gap-3 my-3\"),\n",
    "            dcc.Download(id=\"download-dataframe-csv\"),\n",
    "        ], className=\"container\"),\n",
    "        dbc.Modal(\n",
    "            [\n",
    "                dbc.ModalHeader(dbc.ModalTitle(\"Configure Preprocessing Steps\")),\n",
    "                dbc.ModalBody(id=\"preprocessing-options-modal-body\", children=[\n",
    "                ]),\n",
    "                dbc.ModalFooter([\n",
    "                    dbc.Button(\"Cancel\", id=\"cancel-preprocessing\", color=\"secondary\", className=\"ms-auto\"),\n",
    "                    dbc.Button(\"Apply Changes\", id=\"apply-preprocessing-button\", color=\"success\")\n",
    "                ]),\n",
    "            ],\n",
    "            id=\"preprocessing-options-modal\",\n",
    "            is_open=False,\n",
    "            size=\"lg\",\n",
    "            backdrop=\"static\", \n",
    "        ),\n",
    "        html.Div(className=\"container mt-4\", children=[\n",
    "            dash_table.DataTable(\n",
    "                id='data-table',\n",
    "                columns=[{\"name\": col, \"id\": col} for col in global_df.columns],\n",
    "                data=global_df.to_dict('records'),\n",
    "                page_size=10,\n",
    "                style_table={'overflowX': 'auto', 'marginTop': '20px'},\n",
    "                style_cell={'textAlign': 'center', 'fontFamily': 'sans-serif', 'padding': '8px', 'minWidth': '100px', 'width': '150px', 'maxWidth': '200px'},\n",
    "                style_header={'backgroundColor': '#f8f9fa', 'fontWeight': 'bold', 'border': '1px solid #dee2e6'},\n",
    "                style_data={'border': '1px solid #dee2e6'},\n",
    "                style_data_conditional=[{'if': {'row_index': 'odd'}, 'backgroundColor': '#f2f2f2'}],\n",
    "                filter_action=\"native\",\n",
    "                sort_action=\"native\",\n",
    "                sort_mode=\"multi\",\n",
    "                page_action=\"native\",\n",
    "            )\n",
    "        ]),\n",
    "        dcc.Store(id='selected-preprocessing-methods-store', data=[]),\n",
    "        dcc.Store(id='current-data-store', data=global_df.to_dict('records')), \n",
    "        dcc.Store(id='current-columns-store', data=[{\"name\": col, \"id\": col} for col in global_df.columns]) \n",
    "    ])\n",
    "    return app1 , global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17f7304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8052/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:885: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:903: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:903: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:903: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:903: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:885: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:885: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:885: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n",
      "C:\\Users\\YOUSSEF\\AppData\\Local\\Temp\\ipykernel_11380\\3310272578.py:903: FutureWarning:\n",
      "\n",
      "Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dash\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import html, dcc, Input, Output\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from dash import callback\n",
    "from dash import Dash, html, dcc, callback, Input, Output, State, ctx, ALL\n",
    "\n",
    "external_stylesheets = [\n",
    "    dbc.themes.BOOTSTRAP,\n",
    "    \"https://smart-radius.com/assets/libs/bootstrap/css/bootstrap.rtl.min.css\",\n",
    "    \"https://smart-radius.com/assets/css/styles.css\",\n",
    "    \"https://smart-radius.com/assets/css/icons.min.css\",\n",
    "    \"https://smart-radius.com/assets/css/font_cairo.css\"\n",
    "]\n",
    "\n",
    "global global_df \n",
    "global_df = pd.DataFrame()\n",
    "# Main Dash app\n",
    "app = dash.Dash(__name__,\n",
    "                external_stylesheets=external_stylesheets,\n",
    "                suppress_callback_exceptions=True,\n",
    "                title=\"Multi-Page & Preprocessing App\")\n",
    "\n",
    "server = app.server\n",
    "\n",
    "# Sidebar and content styles\n",
    "SIDEBAR_STYLE = {\n",
    "    \"position\": \"fixed\",\n",
    "    \"top\": 0,\n",
    "    \"left\": 0,\n",
    "    \"bottom\": 0,\n",
    "    \"width\": \"18rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "    \"background-color\": \"#f8f9fa\",\n",
    "    \"overflow-y\": \"auto\",\n",
    "}\n",
    "CONTENT_STYLE = {\n",
    "    \"margin-left\": \"19rem\",\n",
    "    \"margin-right\": \"1rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "}\n",
    "\n",
    "# Sidebar navigation\n",
    "sidebar = html.Div(\n",
    "    [\n",
    "        html.H2(\"SKY AI\", className=\"display-6 text-center\"),\n",
    "        html.Hr(),\n",
    "        html.P(\"Select a page:\", className=\"lead text-center\"),\n",
    "        dbc.Nav(\n",
    "            [\n",
    "                dbc.NavLink(\"Home\", href=\"/\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Report In Data\", href=\"/contact\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Data Preprocessing\", href=\"/preprocessing\", active=\"exact\"),\n",
    "                dbc.NavLink(\" Model Training\", href=\"/data-exploration\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Model Test\", href=\"/test\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Anime Recommendation System\", href=\"/another-page\", active=\"exact\"),\n",
    "            ],\n",
    "            vertical=True,\n",
    "            pills=True,\n",
    "        ),\n",
    "    ],\n",
    "    style=SIDEBAR_STYLE,\n",
    ")\n",
    "\n",
    "# Main layout\n",
    "app.layout = html.Div([\n",
    "    dcc.Location(id=\"url\", refresh=False),\n",
    "    sidebar,\n",
    "    html.Div(id=\"page-content\", style=CONTENT_STYLE)\n",
    "])\n",
    "\n",
    "\n",
    "# Callbacks for multi-page navigation\n",
    "@app.callback(\n",
    "    Output(\"page-content\", \"children\"),\n",
    "    [Input(\"url\", \"pathname\")]\n",
    ")\n",
    "def display_page(pathname):\n",
    "    global global_df\n",
    "    if pathname == \"/\":\n",
    "        return get_home_layout()\n",
    "    elif pathname == \"/data-exploration\":\n",
    "        return get_data_exploration_layout()\n",
    "    elif pathname == \"/preprocessing\":\n",
    "        \n",
    "        app11 , global_df =get_preprocessing_layout()\n",
    "        return app11\n",
    "    elif pathname == \"/another-page\":\n",
    "        return get_another_page_layout()\n",
    "    elif pathname == \"/contact\":\n",
    "        return get_contact_layout(global_df)\n",
    "    elif pathname == \"/test\":\n",
    "        return test()\n",
    "    else:\n",
    "        return dbc.Container([\n",
    "            html.H1(\"404: Page Not Found\", className=\"text-danger\"),\n",
    "            html.Hr(),\n",
    "            html.P(f\"The pathname '{pathname}' was not recognised...\"),\n",
    "            html.P(\"Please select a page from the menu.\"),\n",
    "        ], className=\"py-5 text-center\")\n",
    "\n",
    "@app.callback(\n",
    "    Output('output', 'children'),\n",
    "    Input('print-button', 'n_clicks'),\n",
    "    Input('text-input', 'value')\n",
    ")\n",
    "def update_output(n_clicks, value):\n",
    "    if n_clicks == 0:\n",
    "        return \"\"\n",
    "    if not value:\n",
    "        return \"⚠️ \"\n",
    "    return f\"✅  {value}\" \n",
    "# --- Callback to Reset Data  ---\n",
    "@callback(\n",
    "    Output('current-data-store', 'data', allow_duplicate=True),\n",
    "    Output('current-columns-store', 'data', allow_duplicate=True),\n",
    "    Output('data-table', 'data', allow_duplicate=True),\n",
    "    Output('data-table', 'columns', allow_duplicate=True),\n",
    "    Output('preprocessing-dropdown', 'value', allow_duplicate=True), # Added allow_duplicate=True\n",
    "    Input('reset-data-button', 'n_clicks'), # Keep this line IF you intend to keep the old reset button ID somewhere else or reuse it\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def reset_data(n_clicks):\n",
    "    # Check if the trigger was indeed the reset button (if you keep the input)\n",
    "    # triggered_id = ctx.triggered_id\n",
    "    # if n_clicks and triggered_id == 'reset-data-button':\n",
    "    if n_clicks: # If you keep the original Input for reset-data-button\n",
    "        print(\"Resetting data to original state.\")\n",
    "        columns = [{\"name\": col, \"id\": col} for col in global_df.columns]\n",
    "        data = global_df.to_dict('records')\n",
    "        # Reset stored data, table data, table columns, and dropdown\n",
    "        return data, columns, data, columns, []\n",
    "    # If triggered by something else or n_clicks is None/0\n",
    "    return no_update, no_update, no_update, no_update, no_update\n",
    "\n",
    "\n",
    "# --- Callback to Open Modal and Generate Options ---\n",
    "@callback(\n",
    "    Output(\"preprocessing-options-modal\", \"is_open\"),\n",
    "    Output(\"preprocessing-options-modal-body\", \"children\"),\n",
    "    Output('selected-preprocessing-methods-store', 'data'), # Store selected methods\n",
    "    Input(\"open-modal-button\", \"n_clicks\"),\n",
    "    Input(\"cancel-preprocessing\", \"n_clicks\"),\n",
    "    State(\"preprocessing-dropdown\", \"value\"), # Get methods selected in dropdown\n",
    "    State(\"preprocessing-options-modal\", \"is_open\"),\n",
    "    State(\"current-columns-store\", \"data\"), # Get current columns\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def toggle_modal_and_generate_options(n_open, n_cancel, selected_methods, is_open, current_columns_list):\n",
    "    triggered_id = ctx.triggered_id\n",
    "    print(f\"Modal Triggered ID: {triggered_id}\")\n",
    "\n",
    "    if triggered_id == \"open-modal-button\" and selected_methods:\n",
    "        modal_content = []\n",
    "        # Ensure current_columns_list is not None and is a list of dicts\n",
    "        if current_columns_list and isinstance(current_columns_list, list):\n",
    "             current_columns = [col['id'] for col in current_columns_list if isinstance(col, dict) and 'id' in col]\n",
    "        else:\n",
    "             print(\"Warning: current_columns_list is invalid or empty.\")\n",
    "             current_columns = [] # Fallback to empty list\n",
    "\n",
    "        if not current_columns:\n",
    "             # Attempt to get columns from global_df as a last resort if store is empty/invalid\n",
    "             current_columns = global_df.columns.tolist()\n",
    "             print(\"Warning: Using columns from global_df as fallback.\")\n",
    "\n",
    "\n",
    "        for method in selected_methods:\n",
    "            # Ensure method is a string before using replace\n",
    "            if not isinstance(method, str):\n",
    "                 print(f\"Warning: Skipping invalid method value: {method}\")\n",
    "                 continue\n",
    "\n",
    "            method_div = [html.H5(f\"Options for: {method.replace('_', ' ').title()}\", className=\"mt-3\"), html.Hr()]\n",
    "\n",
    "            # --- Column Selector for the method ---\n",
    "            method_div.append(html.Label(f\"Select columns to apply '{method.replace('_', ' ').title()}' on:\"))\n",
    "            method_div.append(\n",
    "                dcc.Dropdown(\n",
    "                    options=[{\"label\": c, \"value\": c} for c in current_columns],\n",
    "                    value=[], # Start with no columns selected\n",
    "                    multi=True,\n",
    "                    id={'type': 'method-column-selector', 'index': method}\n",
    "                )\n",
    "            )\n",
    "            method_div.append(html.Br()) # Add some space\n",
    "\n",
    "            # --- Specific Options based on method ---\n",
    "            if method == \"Normalization\":\n",
    "                method_div.append(html.Label(\"Normalization Type:\"))\n",
    "                method_div.append(dcc.RadioItems(\n",
    "                    options=[\n",
    "                        {'label': ' Min-Max (Scales to [0, 1])', 'value': 'min_max'},\n",
    "                        {'label': ' Z-Score (Standard Scaler)', 'value': 'z_score'} # Note: Z-score *is* Standardization\n",
    "                    ],\n",
    "                    value='min_max', # Default value\n",
    "                    id={'type': 'method-option', 'index': f\"{method}-type\"},\n",
    "                    inline=True, # Use inline or list based on preference\n",
    "                    # Consider using dbc.RadioItems for better Bootstrap integration\n",
    "                ))\n",
    "            elif method == \"Encoding\":\n",
    "                method_div.append(html.Label(\"Encoding Type:\"))\n",
    "                method_div.append(dcc.RadioItems(\n",
    "                    options=[\n",
    "                         {'label': ' One-Hot Encoding', 'value': 'one_hot'},\n",
    "                         {'label': ' Label Encoding', 'value': 'label'}\n",
    "                    ],\n",
    "                     value='one_hot', # Default value\n",
    "                     id={'type': 'method-option', 'index': f\"{method}-type\"},\n",
    "                     inline=True\n",
    "                ))\n",
    "            elif method == \"drop_feature\":\n",
    "                 # Modify the label slightly for clarity\n",
    "                 method_div[1] = html.Label(f\"Select columns (features) to drop:\") # Modify the label generated above\n",
    "            elif method == \"pca\":\n",
    "                method_div.append(html.Label(\"Number of Components (<= number of selected numeric columns):\"))\n",
    "                method_div.append(dbc.Input( # Use dbc.Input for better styling\n",
    "                     type=\"number\",\n",
    "                     min=1,\n",
    "                     step=1,\n",
    "                     placeholder=\"Enter number of components\",\n",
    "                     id={'type': 'method-option', 'index': f\"{method}-components\"}\n",
    "                ))\n",
    "\n",
    "            modal_content.append(dbc.Card(dbc.CardBody(method_div), className=\"mb-3\"))\n",
    "\n",
    "        if not modal_content:\n",
    "             modal_content = [html.P(\"Please select at least one preprocessing method from the dropdown.\")]\n",
    "             return False, modal_content, no_update\n",
    "        return True, modal_content, selected_methods\n",
    "\n",
    "    elif triggered_id == \"cancel-preprocessing\":\n",
    "         print(\"Cancel button clicked.\")\n",
    "         return False, no_update, no_update\n",
    "    elif triggered_id == \"open-modal-button\" and not selected_methods:\n",
    "        return False, html.P(\"Please select preprocessing methods first.\", className=\"text-danger\"), []\n",
    "    return is_open, no_update, no_update\n",
    "\n",
    "\n",
    "# --- Callback for Applying Preprocessing Steps ---\n",
    "@callback(\n",
    "    Output('current-data-store', 'data', allow_duplicate=True),    \n",
    "    Output('current-columns-store', 'data', allow_duplicate=True), \n",
    "    Output('data-table', 'data', allow_duplicate=True),            \n",
    "    Output('data-table', 'columns', allow_duplicate=True),         \n",
    "    Output(\"preprocessing-options-modal\", \"is_open\", allow_duplicate=True), \n",
    "    Output(\"preprocessing-options-modal-body\", \"children\", allow_duplicate=True), \n",
    "    Input(\"apply-preprocessing-button\", \"n_clicks\"),\n",
    "    State('selected-preprocessing-methods-store', 'data'),         \n",
    "    State({'type': 'method-column-selector', 'index': ALL}, 'value'),\n",
    "    State({'type': 'method-column-selector', 'index': ALL}, 'id'),    \n",
    "    State({'type': 'method-option', 'index': ALL}, 'value'),          \n",
    "    State({'type': 'method-option', 'index': ALL}, 'id'),            \n",
    "    State('current-data-store', 'data'),                            \n",
    "    prevent_initial_call=True,\n",
    "    allow_duplicate=True,\n",
    ")\n",
    "def apply_preprocessing_steps(n_clicks,\n",
    "                              selected_methods,\n",
    "                              column_selector_values, column_selector_ids,\n",
    "                              option_values, option_ids,\n",
    "                              current_data_records):\n",
    "    if n_clicks is None or not selected_methods:\n",
    "        print(\"Apply button not clicked or no methods selected in store.\")\n",
    "        return no_update, no_update, no_update, no_update, False, []\n",
    "\n",
    "    print(\"\\n--- Applying Preprocessing ---\")\n",
    "    print(f\"Methods selected in store: {selected_methods}\")\n",
    "    if not current_data_records:\n",
    "         print(\"Error: No current data found in store. Cannot apply preprocessing.\")\n",
    "         return no_update, no_update, no_update, no_update, False, html.P(\"Error: Data store is empty.\", className=\"text-danger\")\n",
    "    processed_df = pd.DataFrame.from_records(current_data_records)\n",
    "    method_columns = {}\n",
    "    if column_selector_ids and column_selector_values:\n",
    "         method_columns = {comp_id['index']: value for comp_id, value in zip(column_selector_ids, column_selector_values) if isinstance(comp_id, dict) and 'index' in comp_id}\n",
    "\n",
    "    method_options = {}\n",
    "    if option_ids and option_values:\n",
    "        method_options = {comp_id['index']: value for comp_id, value in zip(option_ids, option_values) if isinstance(comp_id, dict) and 'index' in comp_id}\n",
    "    print(f\"Columns selected per method: {method_columns}\")\n",
    "    print(f\"Options selected per method: {method_options}\")\n",
    "    errors = [] \n",
    "    for method in selected_methods:\n",
    "        if not isinstance(method, str):\n",
    "             print(f\"Warning: Skipping invalid method value from store: {method}\")\n",
    "             continue\n",
    "        print(f\"\\nProcessing: {method}\")\n",
    "        columns_to_process = method_columns.get(method, [])\n",
    "        if columns_to_process is None:\n",
    "             columns_to_process = []\n",
    "        elif not isinstance(columns_to_process, list):\n",
    "             columns_to_process = [columns_to_process] \n",
    "        valid_columns_to_process = [col for col in columns_to_process if col in processed_df.columns]\n",
    "        if len(valid_columns_to_process) != len(columns_to_process):\n",
    "            print(f\"  - Warning: Some selected columns for '{method}' do not exist in the current dataframe. Processing only valid columns: {valid_columns_to_process}\")\n",
    "        columns_to_process = valid_columns_to_process \n",
    "\n",
    "\n",
    "        if not columns_to_process and method not in ['remove_null', 'remove_duplicates']:\n",
    "             print(f\"  - Skipping '{method}': No valid columns selected or available for processing.\")\n",
    "             continue \n",
    "        try:\n",
    "            if method == \"remove_null\":\n",
    "                subset_to_check = columns_to_process if columns_to_process else None #\n",
    "                print(f\"  - Removing rows with nulls in columns: {'all' if subset_to_check is None else subset_to_check}\")\n",
    "                initial_rows = len(processed_df)\n",
    "                processed_df.dropna(subset=subset_to_check, inplace=True)\n",
    "                print(f\"  - Rows removed: {initial_rows - len(processed_df)}\")\n",
    "            elif method == \"remove_duplicates\":\n",
    "                subset_to_check = columns_to_process if columns_to_process else None \n",
    "                print(f\"  - Removing duplicate rows based on columns: {'all' if subset_to_check is None else subset_to_check}\")\n",
    "                initial_rows = len(processed_df)\n",
    "                processed_df.drop_duplicates(subset=subset_to_check, inplace=True)\n",
    "                print(f\"  - Rows removed: {initial_rows - len(processed_df)}\")\n",
    "            elif method == \"Normalization\":\n",
    "                norm_type = method_options.get(f\"{method}-type\", \"min_max\") \n",
    "                print(f\"  - Applying {norm_type} normalization to columns: {columns_to_process}\")\n",
    "                numeric_cols = processed_df[columns_to_process].select_dtypes(include=np.number).columns.tolist()\n",
    "                if not numeric_cols:\n",
    "                    print(\"  - Warning: No numeric columns selected or valid for Normalization.\")\n",
    "                    continue\n",
    "                print(f\"    - Numeric columns being processed: {numeric_cols}\")\n",
    "                if norm_type == \"min_max\":\n",
    "                    scaler = MinMaxScaler()\n",
    "                    processed_df[numeric_cols] = scaler.fit_transform(processed_df[numeric_cols])\n",
    "                elif norm_type == \"z_score\": \n",
    "                    scaler = StandardScaler()\n",
    "                    processed_df[numeric_cols] = scaler.fit_transform(processed_df[numeric_cols])\n",
    "            elif method == \"Standardization\":\n",
    "                 print(f\"  - Applying Standardization (Z-Score) to columns: {columns_to_process}\")\n",
    "                 numeric_cols = processed_df[columns_to_process].select_dtypes(include=np.number).columns.tolist()\n",
    "                 if not numeric_cols:\n",
    "                    print(\"  - Warning: No numeric columns selected or valid for Standardization.\")\n",
    "                    continue\n",
    "                 print(f\"    - Numeric columns being processed: {numeric_cols}\")\n",
    "                 scaler = StandardScaler()\n",
    "                 processed_df[numeric_cols] = scaler.fit_transform(processed_df[numeric_cols])\n",
    "            elif method == \"Encoding\":\n",
    "                encoding_type = method_options.get(f\"{method}-type\", \"one_hot\") \n",
    "                print(f\"  - Applying {encoding_type} encoding to columns: {columns_to_process}\")\n",
    "                categorical_cols = processed_df[columns_to_process].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "                if not categorical_cols:\n",
    "                     print(\"  - Warning: No categorical columns (object/category) selected or valid for Encoding.\")\n",
    "                     continue\n",
    "                print(f\"    - Categorical columns being processed: {categorical_cols}\")\n",
    "\n",
    "                if encoding_type == \"label\":\n",
    "                    for col in categorical_cols:\n",
    "                        le = LabelEncoder()\n",
    "                        processed_df[col] = le.fit_transform(processed_df[col].astype(str))\n",
    "                        print(f\"      - Applied Label Encoding to '{col}'\")\n",
    "                elif encoding_type == \"one_hot\":\n",
    "                    cols_to_encode = [col for col in categorical_cols if col in processed_df.columns]\n",
    "                    if cols_to_encode:\n",
    "                        try:\n",
    "                            processed_df = pd.get_dummies(processed_df, columns=cols_to_encode, prefix=cols_to_encode, prefix_sep='_ohe_') \n",
    "                            print(f\"      - Applied One-Hot Encoding, dropped original columns: {cols_to_encode}\")\n",
    "                        except Exception as e_ohe:\n",
    "                             error_msg = f\"Error during One-Hot Encoding for columns '{cols_to_encode}': {e_ohe}\"\n",
    "                             print(f\"  - !!! {error_msg}\")\n",
    "                             errors.append(error_msg)\n",
    "                    else:\n",
    "                        print(f\"      - Columns specified for One-Hot Encoding not found or already processed: {categorical_cols}\")\n",
    "            elif method == \"drop_feature\":\n",
    "                print(f\"  - Dropping features (columns): {columns_to_process}\")\n",
    "                if columns_to_process: \n",
    "                    processed_df.drop(columns=columns_to_process, inplace=True)\n",
    "                    print(f\"    - Dropped: {columns_to_process}\")\n",
    "                else:\n",
    "                    print(f\"    - No valid columns specified or found for dropping.\")\n",
    "            elif method == \"pca\":\n",
    "                n_components_str = method_options.get(f\"{method}-components\")\n",
    "                print(f\"  - Applying PCA to columns: {columns_to_process}\")\n",
    "                numeric_cols = processed_df[columns_to_process].select_dtypes(include=np.number).columns.tolist()\n",
    "                if not numeric_cols:\n",
    "                    print(\"  - Warning: No numeric columns selected or valid for PCA.\")\n",
    "                    continue\n",
    "                if not n_components_str:\n",
    "                     print(\"  - Skipping PCA: Number of components not specified.\")\n",
    "                     errors.append(f\"PCA skipped for columns '{columns_to_process}': Number of components not specified.\")\n",
    "                     continue\n",
    "                try:\n",
    "                    n_components = int(n_components_str) \n",
    "                except (ValueError, TypeError):\n",
    "                    print(f\"  - Skipping PCA: Invalid number of components specified: '{n_components_str}'. Must be an integer.\")\n",
    "                    errors.append(f\"PCA skipped for columns '{columns_to_process}': Invalid number of components '{n_components_str}'.\")\n",
    "                    continue\n",
    "                if n_components <= 0:\n",
    "                    print(\"  - Skipping PCA: Number of components must be positive.\")\n",
    "                    errors.append(f\"PCA skipped for columns '{columns_to_process}': Number of components ({n_components}) must be positive.\")\n",
    "                    continue\n",
    "                if n_components > len(numeric_cols):\n",
    "                    print(f\"  - Warning: Number of components ({n_components}) is greater than the number of selected numeric features ({len(numeric_cols)}). Setting components to {len(numeric_cols)}.\")\n",
    "                    n_components = len(numeric_cols) \n",
    "                if n_components == 0:\n",
    "                     print(\"  - Skipping PCA: No valid numeric features available after validation.\")\n",
    "                     continue\n",
    "                print(f\"    - Numeric columns being processed: {numeric_cols}\")\n",
    "                print(f\"    - Number of components: {n_components}\")\n",
    "                pca_data = processed_df[numeric_cols].copy()\n",
    "                if pca_data.isnull().values.any():\n",
    "                    print(\"    - Warning: NaN values found in PCA columns. Filling with column mean.\")\n",
    "                    for col in numeric_cols:\n",
    "                        if pca_data[col].isnull().any():\n",
    "                            pca_data[col].fillna(pca_data[col].mean(), inplace=True)\n",
    "                pca_data = pca_data.astype(float)\n",
    "                pca = PCA(n_components=n_components)\n",
    "                pca_result = pca.fit_transform(pca_data)\n",
    "                pca_cols = [f\"PCA_{i+1}\" for i in range(n_components)]\n",
    "                pca_df = pd.DataFrame(pca_result, columns=pca_cols, index=pca_data.index)\n",
    "                cols_to_drop_pca = [col for col in numeric_cols if col in processed_df.columns]\n",
    "                processed_df.drop(columns=cols_to_drop_pca, inplace=True)\n",
    "                processed_df = pd.concat([processed_df, pca_df], axis=1)\n",
    "                print(f\"    - Dropped original columns: {cols_to_drop_pca}\")\n",
    "                print(f\"    - Added PCA columns: {pca_cols}\")\n",
    "        except Exception as e:\n",
    "             error_msg = f\"Error processing method '{method}' on columns '{columns_to_process}': {e}\"\n",
    "             print(f\"  - !!! {error_msg}\")\n",
    "             import traceback\n",
    "             traceback.print_exc()\n",
    "             errors.append(error_msg)\n",
    "    print(\"\\n--- Preprocessing Complete ---\")\n",
    "    modal_feedback = [] \n",
    "    if errors:\n",
    "        print(\"Errors occurred during processing:\")\n",
    "        error_items = [html.Li(err) for err in errors]\n",
    "        modal_feedback = [html.Div([\n",
    "             html.H5(\"Processing Errors Occurred:\", className=\"text-danger\"),\n",
    "             html.Ul(error_items)\n",
    "             ], className=\"alert alert-danger\")] \n",
    "        for err in errors:\n",
    "            print(f\"- {err}\")\n",
    "    final_columns = [{\"name\": col, \"id\": col} for col in processed_df.columns]\n",
    "    final_data = processed_df.to_dict('records')\n",
    "    global global_df\n",
    "    global_df = processed_df.copy()\n",
    "    return final_data, final_columns, final_data, final_columns, False, [] \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "###################################################################################################model coal backe\n",
    "@app.callback(\n",
    "    Output(\"layer-config-modal\", \"is_open\"),\n",
    "    Output(\"dynamic-layer-input-container\", \"children\"),\n",
    "    [Input(\"open-layer-config-modal-button\", \"n_clicks\"),\n",
    "     Input(\"close-layer-config-modal-button\", \"n_clicks\"),\n",
    "     Input(\"save-layer-config-button\", \"n_clicks\")],\n",
    "    [State(\"layer-config-modal\", \"is_open\"),\n",
    "     State(\"dl-num-layers\", \"value\"),\n",
    "     State(\"deep-learning-layer-configs-store\", \"data\")]\n",
    ")\n",
    "def toggle_modal_and_generate_inputs(n_open, n_close, n_save, is_open, num_layers, stored_configs):\n",
    "    ctx = dash.callback_context\n",
    "    triggered_id = ctx.triggered[0]['prop_id'].split('.')[0] if ctx.triggered else None\n",
    "\n",
    "    if not isinstance(num_layers, int) or num_layers < 1:\n",
    "        num_layers = 1 \n",
    "\n",
    "    new_children = []\n",
    "    if triggered_id == \"open-layer-config-modal-button\":\n",
    "        current_configs = stored_configs if stored_configs else []\n",
    "        if len(current_configs) < num_layers:\n",
    "            current_configs.extend([{} for _ in range(num_layers - len(current_configs))])\n",
    "        elif len(current_configs) > num_layers:\n",
    "            current_configs = current_configs[:num_layers]\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            layer_conf = current_configs[i] if i < len(current_configs) else {}\n",
    "            units_value = layer_conf.get('units')\n",
    "            activation_value = layer_conf.get('activation')\n",
    "            \n",
    "            units_label_text = f\"Layer {i+1} Units (Neurons):\"\n",
    "            if num_layers == 1: \n",
    "                 units_label_text = \"Units (e.g., Input Features if first, Output Classes if last):\"\n",
    "            elif i == 0: \n",
    "                 units_label_text = \"Layer 1 Units (Input Shape/Features):\"\n",
    "            elif i == num_layers - 1: \n",
    "                 units_label_text = f\"Layer {num_layers} Units (Number of Output Classes/Values):\"\n",
    "\n",
    "            layer_input_row = dbc.Row([\n",
    "                dbc.Col(html.H6(f\"Layer {i+1} Configuration:\"), width=12, className=\"mt-3 mb-1 text-primary\"),\n",
    "                dbc.Col([\n",
    "                    html.Label(units_label_text),\n",
    "                    dcc.Dropdown(\n",
    "                        id={'type': 'dynamic-layer-units', 'index': i},\n",
    "                        options=common_dense_units,\n",
    "                        value=units_value,\n",
    "                        placeholder=\"Select units/classes for layer\"\n",
    "                    )\n",
    "                ], md=6),\n",
    "                dbc.Col([\n",
    "                    html.Label(\"Activation Function:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id={'type': 'dynamic-layer-activation', 'index': i},\n",
    "                        options=common_activation_functions,\n",
    "                        value=activation_value,\n",
    "                        placeholder=\"Select activation for layer\"\n",
    "                    )\n",
    "                ], md=6)\n",
    "            ], className=\"mb-3 align-items-center border-bottom pb-3\")\n",
    "            new_children.append(layer_input_row)\n",
    "        return True, new_children\n",
    "\n",
    "    if triggered_id in [\"close-layer-config-modal-button\", \"save-layer-config-button\"]:\n",
    "        return False, dash.no_update \n",
    "\n",
    "    return is_open, dash.no_update\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"deep-learning-layer-configs-store\", \"data\"),\n",
    "    Input(\"save-layer-config-button\", \"n_clicks\"),\n",
    "    [State({'type': 'dynamic-layer-units', 'index': ALL}, 'value'),\n",
    "     State({'type': 'dynamic-layer-activation', 'index': ALL}, 'value'),\n",
    "     State(\"dl-num-layers\", \"value\")],\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def save_layer_configurations(n_clicks_save, layer_units_values, layer_activation_values, num_layers):\n",
    "    if n_clicks_save == 0:\n",
    "        return dash.no_update\n",
    "\n",
    "    configurations = []\n",
    "    if num_layers and isinstance(num_layers, int) and num_layers > 0:\n",
    "        safe_units_values = layer_units_values if layer_units_values is not None else []\n",
    "        safe_activation_values = layer_activation_values if layer_activation_values is not None else []\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            units = safe_units_values[i] if i < len(safe_units_values) else None\n",
    "            activation = safe_activation_values[i] if i < len(safe_activation_values) else None\n",
    "            configurations.append({'layer': i + 1, 'units': units, 'activation': activation})\n",
    "    return configurations\n",
    "\n",
    "@app.callback(\n",
    "    [Output('output-message', 'children'),\n",
    "     Output('download-model-button', 'style'),\n",
    "     Output('trained-model-path-store', 'data')],\n",
    "    [Input('train-button', 'n_clicks')],\n",
    "    [State('dl-num-layers', 'value'),\n",
    "     State('deep-learning-layer-configs-store', 'data'),\n",
    "     State('dl-output-column', 'value'),\n",
    "     State('ml-model-name', 'value'),\n",
    "     State('ml-output-column', 'value'),\n",
    "     State('train-dl-checkbox', 'value'),\n",
    "     State('train-ml-checkbox', 'value')]\n",
    ")\n",
    "def handle_train_model(n_clicks, num_dl_layers, dl_layer_configs, dl_output_col, ml_model_name, ml_output_col, train_dl_selected, train_ml_selected):\n",
    "    default_download_style = {'display': 'none'}\n",
    "    no_model_path_stored = None\n",
    "\n",
    "    if n_clicks is None or n_clicks == 0:\n",
    "        return \"Select models to train and click 'Train Selected Models' to begin.\", default_download_style, no_model_path_stored\n",
    "\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered:\n",
    "        return \"Select models to train and click 'Train Selected Models' to begin.\", default_download_style, no_model_path_stored\n",
    "        \n",
    "    output_messages = []\n",
    "    latest_trained_model_path = None\n",
    "    download_button_style = default_download_style.copy()\n",
    "    test_size = 0.2 \n",
    "\n",
    "    X_dl_train, X_dl_test, y_dl_train, y_dl_test = None, None, None, None\n",
    "    if train_dl_selected and dl_output_col:\n",
    "        if dl_output_col in global_df.columns:\n",
    "            y_dl = global_df[dl_output_col]\n",
    "            X_dl = global_df.drop(columns=[dl_output_col])\n",
    "            if len(X_dl) > 1 : # Need at least 2 samples for train_test_split\n",
    "                 X_dl_train, X_dl_test, y_dl_train, y_dl_test = train_test_split(X_dl, y_dl, test_size=test_size, random_state=42)\n",
    "            else:\n",
    "                output_messages.append(html.Div(f\"Warning: Not enough data for DL model to split into training/testing sets (Features: {X_dl.shape[0]}). Using all data for training.\", className=\"text-warning\"))\n",
    "                X_dl_train, y_dl_train = X_dl, y_dl # Use all data if too small\n",
    "                X_dl_test, y_dl_test = X_dl, y_dl # Or handle this case appropriately\n",
    "        else:\n",
    "            output_messages.append(html.Div(f\"Error: DL Target column '{dl_output_col}' not found in data.\", className=\"text-danger\"))\n",
    "            train_dl_selected = False\n",
    "\n",
    "    X_ml_train, X_ml_test, y_ml_train, y_ml_test = None, None, None, None\n",
    "    if train_ml_selected and ml_output_col:\n",
    "        if ml_output_col in global_df.columns:\n",
    "            y_ml = global_df[ml_output_col]\n",
    "            X_ml = global_df.drop(columns=[ml_output_col])\n",
    "            if len(X_ml) > 1:\n",
    "                X_ml_train, X_ml_test, y_ml_train, y_ml_test = train_test_split(X_ml, y_ml, test_size=test_size, random_state=42)\n",
    "            else:\n",
    "                output_messages.append(html.Div(f\"Warning: Not enough data for ML model to split into training/testing sets (Features: {X_ml.shape[0]}). Using all data for training.\", className=\"text-warning\"))\n",
    "                X_ml_train, y_ml_train = X_ml, y_ml\n",
    "                X_ml_test, y_ml_test = X_ml, y_ml \n",
    "        else:\n",
    "            output_messages.append(html.Div(f\"Error: ML Target column '{ml_output_col}' not found in data.\", className=\"text-danger\"))\n",
    "            train_ml_selected = False\n",
    "\n",
    "    if not train_dl_selected and not train_ml_selected:\n",
    "        if not output_messages:\n",
    "            output_messages.append(html.P(\"No model type selected for training, or target column missing for selected models.\"))\n",
    "        return html.Div(output_messages), default_download_style, no_model_path_stored\n",
    "\n",
    "    if train_dl_selected:\n",
    "        if X_dl_train is not None and y_dl_train is not None and X_dl_test is not None and y_dl_test is not None :\n",
    "            if not num_dl_layers or not dl_layer_configs:\n",
    "                output_messages.append(html.Div(\"Deep Learning Model: Configuration missing. Training skipped.\", className=\"text-warning\"))\n",
    "            else:\n",
    "                valid_configs = all(conf.get('units') is not None and conf.get('activation') is not None for conf in dl_layer_configs)\n",
    "                if valid_configs:\n",
    "                    output_messages.append(html.P(\"Starting Deep Learning Model training...\"))\n",
    "                    try:\n",
    "                        dl_result_msg, dl_model_path, dl_accuracy = train_deep_learning_model(X_dl_train, y_dl_train, X_dl_test, y_dl_test, dl_layer_configs, num_dl_layers)\n",
    "                        output_messages.append(html.Div(dl_result_msg, className=\"text-success\"))\n",
    "                        # output_messages.append(html.P(f\"Deep Learning Model Test Accuracy: {dl_accuracy:.4f}\"))\n",
    "                        \n",
    "                        if dl_model_path:\n",
    "                            latest_trained_model_path = dl_model_path\n",
    "                            download_button_style = {'display': 'block', 'margin': 'auto'}\n",
    "                            dl_config_str_parts = [f\"Deep Learning Model - Total Layers: {num_dl_layers}\"]\n",
    "                            dl_config_str_parts.append(\"Layer-wise Configurations:\")\n",
    "                            for config in dl_layer_configs:\n",
    "                                units_info = f\"Units/Classes: {config['units']}\"\n",
    "                                activation_info = f\"Activation: {config['activation']}\"\n",
    "                                dl_config_str_parts.append(f\"  Layer {config['layer']}: {units_info}, {activation_info}\")\n",
    "                            output_messages.append(html.Pre(\"\\n\".join(dl_config_str_parts)))\n",
    "                        else:\n",
    "                            output_messages.append(html.Div(\"DL Model trained, but path not returned from training function.\", className=\"text-warning\"))\n",
    "                    except Exception as e:\n",
    "                        output_messages.append(html.Div(f\"Error during DL training: {str(e)}\", className=\"text-danger\"))\n",
    "                else:\n",
    "                     output_messages.append(html.Div(\"Deep Learning Model: Training skipped due to incomplete layer configurations.\", className=\"text-warning\"))\n",
    "        else:\n",
    "            output_messages.append(html.Div(\"Deep Learning Model: Training data (X or y) not prepared or insufficient for split.\", className=\"text-warning\"))\n",
    "\n",
    "    if train_dl_selected and train_ml_selected: \n",
    "         output_messages.append(html.Hr())\n",
    "\n",
    "    if train_ml_selected:\n",
    "        if X_ml_train is not None and y_ml_train is not None and X_ml_test is not None and y_ml_test is not None:\n",
    "            if not ml_model_name:\n",
    "                output_messages.append(html.Div(\"Machine Learning Model: Model name not selected. Training skipped.\", className=\"text-warning\"))\n",
    "            else:\n",
    "                output_messages.append(html.P(f\"Starting Machine Learning Model training ({ml_model_name})...\"))\n",
    "                try:\n",
    "                    ml_result_msg, ml_model_path, ml_accuracy = train_machine_learning_model(X_ml_train, y_ml_train, X_ml_test, y_ml_test, ml_model_name)\n",
    "                    output_messages.append(html.Div(ml_result_msg, className=\"text-success\"))\n",
    "                    # output_messages.append(html.P(f\"Machine Learning Model ({ml_model_name}) Test Accuracy: {ml_accuracy:.4f}\"))\n",
    "\n",
    "                    if ml_model_path:\n",
    "                        latest_trained_model_path = ml_model_path \n",
    "                        download_button_style = {'display': 'block', 'margin': 'auto'} \n",
    "                        output_messages.append(html.Pre(f\"Machine Learning Model: {ml_model_name}\\nOutput Column: {ml_output_col}\"))\n",
    "                    else:\n",
    "                        output_messages.append(html.Div(f\"ML Model {ml_model_name} trained, but path not returned.\", className=\"text-warning\"))\n",
    "                except Exception as e:\n",
    "                    output_messages.append(html.Div(f\"Error during ML training ({ml_model_name}): {str(e)}\", className=\"text-danger\"))\n",
    "        else:\n",
    "            output_messages.append(html.Div(\"Machine Learning Model: Training data (X or y) not prepared or insufficient for split.\", className=\"text-warning\"))\n",
    "\n",
    "    if not output_messages:\n",
    "         output_messages.append(html.P(\"No models were selected or configured for training.\"))\n",
    "\n",
    "    return html.Div(output_messages), download_button_style, latest_trained_model_path\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"download-model-component\", \"data\"),\n",
    "    Input(\"download-model-button\", \"n_clicks\"),\n",
    "    State(\"trained-model-path-store\", \"data\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def download_trained_model(n_clicks, model_path):\n",
    "    if n_clicks > 0 and model_path:\n",
    "        if os.path.exists(model_path):\n",
    "            return dcc.send_file(model_path)\n",
    "        else:\n",
    "            print(f\"Error: Model file not found at {model_path}\")\n",
    "            # Return a small text file indicating the error to the user for download\n",
    "            error_content = f\"Error: The requested model file was not found on the server at path: {model_path}\"\n",
    "            return dict(content=error_content, filename=\"model_download_error.txt\")\n",
    "    return dash.no_update\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################animy\n",
    "try:\n",
    "    df = pd.read_csv(\"anime_ed.csv\")\n",
    "except FileNotFoundError:\n",
    "  \n",
    "    print(\"WARN: 'anime_ed.csv' not found. Using placeholder data.\")\n",
    "    data_placeholder = {\n",
    "        'name': ['Anime A', 'Anime B', 'Anime C', 'Anime D', 'Anime E', 'Anime F'],\n",
    "        'genres': ['Action,Adventure', 'Comedy,Slice of Life', 'Action,Drama', 'Sci-Fi,Adventure', 'Comedy,Drama', 'Fantasy,Magic'],\n",
    "        'rating': [8.5, 7.9, 9.0, 8.2, 7.5, 8.8],\n",
    "      \n",
    "    }\n",
    "    df = pd.DataFrame(data_placeholder)\n",
    "\n",
    "\n",
    "df[\"genres_list\"] = df[\"genre\"].fillna(\"\").astype(str).str.split(',')\n",
    "df[\"genres_list\"] = df[\"genres_list\"].apply(lambda genre_list: sorted([g.strip() for g in genre_list if g.strip()])) # Sort for consistency\n",
    "\n",
    "\n",
    "all_unique_genres = sorted(list(set(g for sublist in df[\"genres_list\"] for g in sublist)))\n",
    "for genre_col in all_unique_genres:\n",
    "    df[genre_col] = df[\"genres_list\"].apply(lambda L: int(genre_col in L))\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"anime-sub-selection-area\", \"children\"),\n",
    "    Input(\"anime-mode-dropdown\", \"value\")\n",
    ")\n",
    "def render_sub_selection(mode):\n",
    "    if mode == \"mood\":\n",
    "        mood_options_for_dropdown = [{\"label\": genre, \"value\": genre} for genre in all_unique_genres]\n",
    "        return html.Div([\n",
    "            html.Label(\"Select Mood(s)/Genre(s):\", className=\"fw-bold mt-3\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"anime-mood-dropdown\",\n",
    "                options=mood_options_for_dropdown,\n",
    "                multi=True,\n",
    "                placeholder=\"Choose your current mood(s) or desired genre(s)...\"\n",
    "            ),\n",
    "            dbc.Button(\n",
    "                html.Span([html.I(className=\"fas fa-magic me-2\"), \"Get Mood Recommendations\"]),\n",
    "                id=\"recommend-mood-button\", color=\"success\", className=\"mt-3 w-100\"\n",
    "            )\n",
    "        ])\n",
    "    elif mode == \"watched\":\n",
    "        anime_names = sorted(df[\"name\"].dropna().unique())\n",
    "        return html.Div([\n",
    "            html.Label(\"Select Anime You Watched:\", className=\"fw-bold mt-3\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"anime-watched-dropdown\",\n",
    "                options=[{\"label\": name, \"value\": name} for name in anime_names],\n",
    "                placeholder=\"Search your previously watched anime...\"\n",
    "            ),\n",
    "            dbc.Button(\n",
    "                html.Span([html.I(className=\"fas fa-film me-2\"), \"Get Similar Recommendations\"]),\n",
    "                id=\"recommend-watched-button\", color=\"info\", className=\"mt-3 w-100\"\n",
    "            )\n",
    "        ])\n",
    "    return html.Div()\n",
    "\n",
    "\n",
    "def create_anime_card(anime_series, index):\n",
    "    return dbc.Col(dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H5(anime_series['name'], className=\"card-title\"),\n",
    "            html.P(f\"Rating: {anime_series.get('rating', 'N/A')}\", className=\"card-text\"),\n",
    "            html.P(\n",
    "                \"Genres: \" + \", \".join(anime_series.get('genres_list', [])),\n",
    "                className=\"card-text small text-muted\"\n",
    "            )\n",
    "        ])\n",
    "    ], className=\"h-100 shadow-sm mb-3\"), md=4, lg=3, className=\"mb-4\") \n",
    "@app.callback(\n",
    "    Output(\"anime-recommendation-results\", \"children\"),\n",
    "    Input(\"recommend-mood-button\", \"n_clicks\"),\n",
    "    State(\"anime-mood-dropdown\", \"value\"),\n",
    "    State(\"num-recommendations-input\", \"value\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def recommend_by_mood(n_clicks, selected_moods, num_to_recommend):\n",
    "    if not n_clicks: # No button click yet\n",
    "        return \"\"\n",
    "    if not selected_moods:\n",
    "        return dbc.Alert(\"Please select at least one mood/genre.\", color=\"warning\", className=\"mt-3\")\n",
    "\n",
    "    df_copy = df.copy() # Work with a copy\n",
    "\n",
    "    df_copy['Dot'] = df_copy[selected_moods].sum(axis=1)\n",
    "\n",
    "    df_sorted = df_copy.sort_values(by=['Dot', 'rating'], ascending=[False, False])\n",
    "\n",
    "    top_animes = df_sorted[df_sorted['Dot'] > 0].head(num_to_recommend)\n",
    "\n",
    "    if top_animes.empty:\n",
    "        return dbc.Alert(\"No anime found matching the selected mood(s)/genre(s). Try a different combination!\", color=\"info\", className=\"mt-3\")\n",
    "\n",
    "    cards = [create_anime_card(row, idx) for idx, row in top_animes.iterrows()]\n",
    "    return dbc.Row(cards)\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"anime-recommendation-results\", \"children\", allow_duplicate=True), \n",
    "    Input(\"recommend-watched-button\", \"n_clicks\"),\n",
    "    State(\"anime-watched-dropdown\", \"value\"),\n",
    "    State(\"num-recommendations-input\", \"value\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def recommend_by_watched(n_clicks, watched_anime_name, num_to_recommend):\n",
    "    if not n_clicks: \n",
    "        return \"\"\n",
    "    if not watched_anime_name:\n",
    "        return dbc.Alert(\"Please select an anime you have watched.\", color=\"warning\", className=\"mt-3\")\n",
    "\n",
    "    watched_row_df = df[df[\"name\"] == watched_anime_name]\n",
    "    if watched_row_df.empty:\n",
    "        return dbc.Alert(f\"Anime '{watched_anime_name}' not found in the database.\", color=\"danger\", className=\"mt-3\")\n",
    "\n",
    "    watched_genres_set = set(watched_row_df.iloc[0][\"genres_list\"])\n",
    "\n",
    "    if not watched_genres_set:\n",
    "        return dbc.Alert(f\"No genre information available for '{watched_anime_name}' to find similar anime.\", color=\"info\", className=\"mt-3\")\n",
    "\n",
    "    recommendations_df = df[df[\"name\"] != watched_anime_name].copy()\n",
    "\n",
    "    def count_common_genres(genre_list_to_compare):\n",
    "        return len(watched_genres_set.intersection(set(genre_list_to_compare)))\n",
    "\n",
    "    recommendations_df[\"common_genres_count\"] = recommendations_df[\"genres_list\"].apply(count_common_genres)\n",
    "\n",
    "    # Filter out anime with no common genres and sort\n",
    "    # Sort by common_genres_count (desc), then rating (desc)\n",
    "    recommendations_df = recommendations_df[recommendations_df[\"common_genres_count\"] > 0]\n",
    "    recommendations_df = recommendations_df.sort_values(\n",
    "        by=[\"common_genres_count\", \"rating\"],\n",
    "        ascending=[False, False]\n",
    "    ).head(num_to_recommend)\n",
    "\n",
    "    if recommendations_df.empty:\n",
    "        return dbc.Alert(f\"Could not find any similar anime recommendations for '{watched_anime_name}'.\", color=\"info\", className=\"mt-3\")\n",
    "\n",
    "    cards = [create_anime_card(row, idx) for idx, row in recommendations_df.iterrows()]\n",
    "    return dbc.Row(cards)\n",
    "##########################################################################################################plot\n",
    "# --- Callbacks ---\n",
    "\n",
    "from dash import ctx  # لو مش مضافة\n",
    "\n",
    "@app.callback(\n",
    "    Output('data-store', 'data'),\n",
    "    Output('x-axis-dropdown', 'options'),\n",
    "    Output('x-axis-dropdown', 'value'),\n",
    "    Output('x-axis-dropdown1', 'options'),\n",
    "    Output('y-axis-dropdown1', 'options'),\n",
    "    Output('z-axis-dropdown1', 'options'),\n",
    "    Output('color-dropdown', 'options'),\n",
    "    Output('scatter-chart', 'figure'),\n",
    "    Input('upload-data', 'contents'),\n",
    "    State('upload-data', 'filename'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_on_upload(contents, filename):\n",
    "    if contents is None:\n",
    "        return no_update, [], None, [], [], [], [], go.Figure()\n",
    "\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    try:\n",
    "        if 'csv' in filename:\n",
    "            global global_df\n",
    "            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "            global_df=df\n",
    "        elif 'xls' in filename or 'xlsx' in filename: # دعم ملفات اكسل\n",
    "            df = pd.read_excel(io.BytesIO(decoded))\n",
    "            global_df=df\n",
    "        else:\n",
    "            print(\"Unsupported file type\")\n",
    "            return no_update, [], None, [], [], [], [], go.Figure().update_layout(title=\"Unsupported File Type\")\n",
    "\n",
    "        options = [{\"label\": col, \"value\": col} for col in df.columns]\n",
    "        initial_fig = go.Figure()\n",
    "        initial_x_col = None\n",
    "\n",
    "        if not df.empty and len(df.columns) > 0:\n",
    "            initial_x_col = df.columns[0]\n",
    "            initial_fig = plot_distribution_of_clas_in_data(df, initial_x_col)\n",
    "        \n",
    "        # تخزين البيانات كـ JSON string\n",
    "        stored_data = df.to_json(date_format='iso', orient='split')\n",
    "\n",
    "        return stored_data, options, initial_x_col, options, options, options, options, initial_fig\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        return no_update, [], None, [], [], [], [], go.Figure().update_layout(title=f\"Error Processing File: {e}\")\n",
    "\n",
    "# Callback لتحديث الرسم البياني التوزيعي\n",
    "@app.callback(\n",
    "    Output('scatter-chart', 'figure',allow_duplicate=True), # allow_duplicate لتجنب تعارض المخرجات\n",
    "    Input('x-axis-dropdown', 'value'),\n",
    "    Input('data-store', 'data'), # استخدام Input بدلا من State ليتم التحديث عند تغير البيانات أيضا\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_distribution_plot(selected_col, stored_data):\n",
    "    if not selected_col or not stored_data:\n",
    "        return go.Figure().update_layout(title=\"Please select a column or upload data.\")\n",
    "    \n",
    "    # تحويل البيانات من JSON string مرة أخرى إلى DataFrame\n",
    "    df = pd.read_json(stored_data, orient='split')\n",
    "    \n",
    "    return plot_distribution_of_clas_in_data(df, selected_col)\n",
    "\n",
    "# Callback لتحديث الرسم البياني ثلاثي الأبعاد\n",
    "@app.callback(\n",
    "    Output('3D-chart', 'figure'),\n",
    "    Input('x-axis-dropdown1', 'value'),\n",
    "    Input('y-axis-dropdown1', 'value'),\n",
    "    Input('z-axis-dropdown1', 'value'),\n",
    "    Input('color-dropdown', 'value'),\n",
    "    Input('data-store', 'data'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def update_3d_plot(x_col, y_col, z_col, color_col, stored_data):\n",
    "    if not stored_data or not x_col or not y_col or not z_col:\n",
    "        return go.Figure().update_layout(title=\"Please select X, Y, and Z axes for the 3D plot and upload data.\")\n",
    "\n",
    "    df = pd.read_json(stored_data, orient='split')\n",
    "\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # التأكد من وجود الأعمدة في الـ DataFrame\n",
    "    if not all(col in df.columns for col in [x_col, y_col, z_col]):\n",
    "        return go.Figure().update_layout(title=\"One or more selected columns not found in data for 3D plot.\")\n",
    "\n",
    "    marker_config = {'size': 5}\n",
    "    if color_col and color_col in df.columns:\n",
    "        # التأكد أن عمود اللون رقمي إذا كان سيُستخدم لمقياس لوني مستمر\n",
    "        if pd.api.types.is_numeric_dtype(df[color_col]):\n",
    "            marker_config['color'] = df[color_col]\n",
    "            marker_config['colorscale'] = 'Viridis' # مثال لمقياس لوني\n",
    "            marker_config['showscale'] = True\n",
    "        else: # إذا كان عمود اللون فئويًا، يمكن استخدامه لتلوين الفئات المختلفة بألوان مميزة\n",
    "            # هذا يتطلب منطقًا أكثر تعقيدًا لتعيين الألوان، حاليًا سنستخدمه كما هو وسيعامله Plotly\n",
    "            marker_config['color'] = df[color_col].astype('category').cat.codes # تحويل الفئات إلى أرقام\n",
    "            # يمكنك إضافة colorscale مخصص هنا إذا أردت\n",
    "            print(f\"Warning: Categorical color column '{color_col}' used. Colors might not be distinct without custom mapping.\")\n",
    "\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=df[x_col],\n",
    "        y=df[y_col],\n",
    "        z=df[z_col],\n",
    "        mode='markers',\n",
    "        marker=marker_config\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"3D Scatter Plot: {x_col} vs {y_col} vs {z_col}\",\n",
    "        scene=dict(\n",
    "            xaxis_title=x_col,\n",
    "            yaxis_title=y_col,\n",
    "            zaxis_title=z_col\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=0, t=40) # تعديل الهوامش\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "##########################################################model tsest\n",
    "# --- Callbacks ---\n",
    "\n",
    "# Callback to parse uploaded data CSV\n",
    "def parse_contents(contents, filename):\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    try:\n",
    "        if 'csv' in filename:\n",
    "            # Assume Csv file\n",
    "            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "        elif 'xls' in filename or 'xlsx' in filename:\n",
    "            # Assume an Excel file\n",
    "            df = pd.read_excel(io.BytesIO(decoded))\n",
    "        else:\n",
    "            return None, html.Div(['Invalid file type. Please upload CSV or Excel.'])\n",
    "        return df, html.Div([f'{filename} uploaded successfully.'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, html.Div(['There was an error processing this file.'])\n",
    "\n",
    "@app.callback(\n",
    "    [Output('data-store1', 'data'),\n",
    "     Output('output-data-upload-status', 'children'),\n",
    "     Output('column-dropdown', 'options'),\n",
    "     Output('column-dropdown', 'value')],\n",
    "    [Input('upload-data', 'contents')],\n",
    "    [State('upload-data', 'filename')],\n",
    "    allow_duplicate=True  \n",
    ")\n",
    "def update_data_output(contents, filename):\n",
    "    if contents is not None:\n",
    "        df, status_message = parse_contents(contents, filename)\n",
    "        if df is not None:\n",
    "            if 'actual' not in df.columns:\n",
    "                return (None,\n",
    "                        html.Div(['Error: CSV file must contain an \"actual\" column.']),\n",
    "                        [], None)\n",
    "\n",
    "            # Get categorical and numerical columns (excluding 'actual') for dropdown\n",
    "            # You might want to refine this logic based on your specific needs\n",
    "            potential_cols = [col for col in df.columns if col != 'actual'] # and df[col].dtype == 'object' or df[col].nunique() < 20]\n",
    "            options = [{'label': col, 'value': col} for col in potential_cols]\n",
    "            default_value = options[0]['value'] if options else None\n",
    "            return df.to_json(date_format='iso', orient='split'), status_message, options, default_value\n",
    "    return None, \"Upload a data file (CSV).\", [], None\n",
    "\n",
    "\n",
    "# Callback to load the uploaded model\n",
    "@app.callback(\n",
    "    [Output('model-status-store', 'data'),\n",
    "     Output('output-model-upload-status', 'children')],\n",
    "    [Input('upload-model', 'contents')],\n",
    "    [State('upload-model', 'filename')]\n",
    ")\n",
    "def update_model_output(contents, filename):\n",
    "    global loaded_model\n",
    "    if contents is not None:\n",
    "        content_type, content_string = contents.split(',')\n",
    "        decoded = base64.b64decode(content_string)\n",
    "        try:\n",
    "            # Assuming the model is saved with joblib or pickle\n",
    "            # For joblib, it's better to use BytesIO\n",
    "            model_file = io.BytesIO(decoded)\n",
    "            loaded_model = joblib.load(model_file) # Or pickle.load(model_file)\n",
    "            status_message = html.Div([f'{filename} model loaded successfully.'])\n",
    "            return {'status': 'loaded', 'filename': filename}, status_message\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            loaded_model = None\n",
    "            return {'status': 'error'}, html.Div(['There was an error loading the model. Ensure it is a .pkl or .joblib file.'])\n",
    "    loaded_model = None # Reset if no content\n",
    "    return {'status': 'empty'}, \"Upload a model file (.pkl, .joblib).\"\n",
    "\n",
    "\n",
    "# Callback to process data with model and calculate metrics\n",
    "@app.callback(\n",
    "    [Output('processed-data-store', 'data'),\n",
    "     Output('metrics-store', 'data'),\n",
    "     Output('analysis-section', 'style')], # Show analysis section\n",
    "    [Input('data-store1', 'data'),\n",
    "     Input('model-status-store', 'data')]\n",
    ")\n",
    "def process_data_with_model(jsonified_data, model_status):\n",
    "    global loaded_model\n",
    "    ctx = dash.callback_context\n",
    "    if not ctx.triggered or jsonified_data is None or model_status is None or model_status.get('status') != 'loaded' or loaded_model is None:\n",
    "        return None, None, {'display': 'none'} # Keep section hidden\n",
    "\n",
    "    df = pd.read_json(jsonified_data, orient='split')\n",
    "\n",
    "    # Prepare features for prediction (assuming all columns except 'actual' are features)\n",
    "    # This might need adjustment based on how your model was trained.\n",
    "    if 'actual' not in df.columns:\n",
    "        print(\"Error: 'actual' column not found in data for prediction.\")\n",
    "        return None, None, {'display': 'none'}\n",
    "\n",
    "    feature_columns = [col for col in df.columns if col != 'actual']\n",
    "    if not feature_columns:\n",
    "        print(\"Error: No feature columns found in data for prediction.\")\n",
    "        return None, None, {'display': 'none'}\n",
    "\n",
    "    X_test = df[feature_columns]\n",
    "    y_actual = df['actual']\n",
    "\n",
    "    try:\n",
    "        predictions = loaded_model.predict(X_test)\n",
    "        df['predicted'] = predictions\n",
    "        df['is_correct'] = (df['actual'] == df['predicted'])\n",
    "\n",
    "        # Calculate overall metrics\n",
    "        accuracy = accuracy_score(y_actual, predictions)\n",
    "        f1 = f1_score(y_actual, predictions, average='weighted') # use 'binary' or 'micro' if appropriate\n",
    "        num_correct = int(df['is_correct'].sum())\n",
    "        num_incorrect = len(df) - num_correct\n",
    "\n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'num_correct': num_correct,\n",
    "            'num_incorrect': num_incorrect,\n",
    "            'total_samples': len(df)\n",
    "        }\n",
    "        return df.to_json(date_format='iso', orient='split'), metrics, {'display': 'block'} # Show section\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction or metrics calculation: {e}\")\n",
    "        return None, None, {'display': 'none'}\n",
    "\n",
    "\n",
    "# Callback for Plot 1: Bar Chart\n",
    "@app.callback(\n",
    "    Output('plot1-bar-chart', 'figure'),\n",
    "    [Input('processed-data-store', 'data'),\n",
    "     Input('column-dropdown', 'value')]\n",
    ")\n",
    "def update_plot1(jsonified_processed_data, selected_column):\n",
    "    if jsonified_processed_data is None or selected_column is None:\n",
    "        return go.Figure(layout={\"title\": \"Plot 1: Upload data and model, then select a column.\"})\n",
    "\n",
    "    df = pd.read_json(jsonified_processed_data, orient='split')\n",
    "    if selected_column not in df.columns:\n",
    "        return go.Figure(layout={\"title\": f\"Plot 1: Column '{selected_column}' not found.\"})\n",
    "\n",
    "    # Calculate counts of correct and incorrect predictions for each unique value in the selected column\n",
    "    grouped_data = df.groupby([selected_column, 'is_correct']).size().reset_index(name='count')\n",
    "\n",
    "    # Pivot the data for a stacked bar chart\n",
    "    pivot_df = grouped_data.pivot(index=selected_column, columns='is_correct', values='count').fillna(0)\n",
    "    # Ensure columns for True (Correct) and False (Incorrect) exist\n",
    "    if True not in pivot_df.columns: pivot_df[True] = 0\n",
    "    if False not in pivot_df.columns: pivot_df[False] = 0\n",
    "\n",
    "    pivot_df = pivot_df.rename(columns={True: 'Correct', False: 'Incorrect'})\n",
    "\n",
    "    fig = go.Figure()\n",
    "    if 'Correct' in pivot_df.columns:\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=pivot_df.index.astype(str), # Ensure x-axis is treated as categorical\n",
    "            y=pivot_df['Correct'],\n",
    "            name='Correct',\n",
    "            marker_color='green'\n",
    "        ))\n",
    "    if 'Incorrect' in pivot_df.columns:\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=pivot_df.index.astype(str),\n",
    "            y=pivot_df['Incorrect'],\n",
    "            name='Incorrect',\n",
    "            marker_color='red'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        title_text=f\"Prediction Correctness for '{selected_column}'\",\n",
    "        xaxis_title=selected_column,\n",
    "        yaxis_title=\"Number of Predictions\",\n",
    "        xaxis={'type': 'category'} # Explicitly set x-axis type to category\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# Callback for Plot 2: Pie Chart\n",
    "@app.callback(\n",
    "    Output('plot2-pie-chart', 'figure'),\n",
    "    [Input('processed-data-store', 'data'),\n",
    "     Input('column-dropdown', 'value')]\n",
    ")\n",
    "def update_plot2(jsonified_processed_data, selected_column):\n",
    "    if jsonified_processed_data is None or selected_column is None:\n",
    "        return go.Figure(layout={\"title\": \"Plot 2: Upload data and model, then select a column.\"})\n",
    "\n",
    "    df = pd.read_json(jsonified_processed_data, orient='split')\n",
    "    if selected_column not in df.columns:\n",
    "        return go.Figure(layout={\"title\": f\"Plot 2: Column '{selected_column}' not found.\"})\n",
    "\n",
    "\n",
    "    errors_df = df[~df['is_correct']] # ~df['is_correct'] means df['is_correct'] == False\n",
    "\n",
    "    if errors_df.empty:\n",
    "        return go.Figure(data=[go.Pie(labels=['No Errors Found'], values=[1], hole=.3)],\n",
    "                         layout=go.Layout(title_text=f\"No Prediction Errors for '{selected_column}'\"))\n",
    "\n",
    "    error_counts = errors_df[selected_column].value_counts().reset_index()\n",
    "    error_counts.columns = [selected_column, 'error_count']\n",
    "\n",
    "    fig = px.pie(\n",
    "        error_counts,\n",
    "        names=selected_column,\n",
    "        values='error_count',\n",
    "        title=f\"Error Distribution by Category in '{selected_column}'\",\n",
    "        hole=.3 # for a donut chart effect\n",
    "    )\n",
    "    fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "    return fig\n",
    "\n",
    "# Callback for Plot 3: Indicators\n",
    "@app.callback(\n",
    "    Output('plot3-indicators', 'figure'),\n",
    "    [Input('metrics-store', 'data')]\n",
    ")\n",
    "def update_plot3(metrics):\n",
    "    if metrics is None:\n",
    "        return go.Figure(layout={\"title\": \"Plot 3: Performance indicators will appear after processing data with model.\"})\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=metrics.get('accuracy', 0) * 100,\n",
    "        title={'text': \"Model Accuracy (%)\"},\n",
    "        domain={'x': [0, 0.45], 'y': [0.55, 1]},\n",
    "        gauge={'axis': {'range': [None, 100]},\n",
    "               'bar': {'color': \"royalblue\"},\n",
    "               'steps': [\n",
    "                   {'range': [0, 60], 'color': \"lightgray\"},\n",
    "                   {'range': [60, 85], 'color': \"gray\"}],\n",
    "               'threshold': {'line': {'color': \"red\", 'width': 4}, 'thickness': 0.75, 'value': 90}}\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"number\",\n",
    "        value=metrics.get('num_correct', 0),\n",
    "        title={\"text\": \"Number of Correct Predictions\"},\n",
    "        domain={'x': [0.55, 1], 'y': [0.75, 1]} # Adjusted y for better spacing\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"number\",\n",
    "        value=metrics.get('num_incorrect', 0),\n",
    "        title={\"text\": \"Number of Incorrect Predictions\"},\n",
    "        domain={'x': [0.55, 1], 'y': [0.5, 0.70]} # Adjusted y for better spacing\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=metrics.get('f1_score', 0),\n",
    "        title={'text': \"F1 Score (Weighted)\"},\n",
    "        domain={'x': [0, 0.45], 'y': [0, 0.45]},\n",
    "        gauge={'axis': {'range': [None, 1]},\n",
    "               'bar': {'color': \"green\"}}\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        grid={'rows': 2, 'columns': 2, 'pattern': \"independent\"},\n",
    "        height=500 \n",
    "    )\n",
    "\n",
    "    return fig\n",
    "@app.callback(\n",
    "    Output(\"download-data\", \"data\"),\n",
    "    Input(\"download-new-data-button\", \"n_clicks\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def download_new_data(n_clicks):\n",
    "    return dcc.send_data_frame(global_df.to_csv, \"modified_data.csv\", index=False)\n",
    "\n",
    "app.run(debug=True, jupyter_mode=\"external\", port=8052)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6d8c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab791ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c283801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70566741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169ac66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6e815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
